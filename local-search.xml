<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>动手学深度学习12：AlexNet</title>
    <link href="/2023/01/06/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A012%EF%BC%9AAlexNet/"/>
    <url>/2023/01/06/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A012%EF%BC%9AAlexNet/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习12：AlexNet"><a href="#动手学深度学习12：AlexNet" class="headerlink" title="动手学深度学习12：AlexNet"></a>动手学深度学习12：AlexNet</h2><h3 id="AlexNet设计"><a href="#AlexNet设计" class="headerlink" title="AlexNet设计"></a>AlexNet设计</h3><p>AlexNet和LeNet的设计理念非常相似，但也存在显著差异。</p><ol><li>AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。</li><li>AlexNet使用ReLU而不是sigmoid作为其激活函数。</li></ol><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230106161518595.png" alt="LeNet与AlexNet对比"></p><p>AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。 </p><p>一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。 另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。 当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。 相反，ReLU激活函数在正区间的梯度总是1。 </p><p>因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。</p><p>AlexNet通过暂退法（ :numref:<code>sec_dropout</code>）控制全连接层的模型复杂度，而LeNet只使用了权重衰减。 为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。 这使得模型更健壮，更大的样本量有效地减少了过拟合。</p><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> torch<br><span class="hljs-attribute">from</span> torch import nn<br><span class="hljs-attribute">from</span> d2l import torch as d2l<br><br><span class="hljs-attribute">net</span> = nn.Sequential(<br>    <span class="hljs-comment"># 这里使用一个11*11的更大窗口来捕捉对象。</span><br>    <span class="hljs-comment"># 同时，步幅为4，以减少输出的高度和宽度。</span><br>    <span class="hljs-comment"># 另外，输出通道的数目远大于LeNet</span><br>    <span class="hljs-attribute">nn</span>.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">11</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    <span class="hljs-attribute">nn</span>.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    <span class="hljs-comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span><br>    <span class="hljs-attribute">nn</span>.Conv2d(<span class="hljs-number">96</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>), nn.ReLU(),<br>    <span class="hljs-attribute">nn</span>.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    <span class="hljs-comment"># 使用三个连续的卷积层和较小的卷积窗口。</span><br>    <span class="hljs-comment"># 除了最后的卷积层，输出通道的数量进一步增加。</span><br>    <span class="hljs-comment"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span><br>    <span class="hljs-attribute">nn</span>.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    <span class="hljs-attribute">nn</span>.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    <span class="hljs-attribute">nn</span>.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    <span class="hljs-attribute">nn</span>.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    <span class="hljs-attribute">nn</span>.Flatten(),<br>    <span class="hljs-comment"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span><br>    <span class="hljs-attribute">nn</span>.Linear(<span class="hljs-number">6400</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>    <span class="hljs-attribute">nn</span>.Dropout(p=<span class="hljs-number">0</span>.<span class="hljs-number">5</span>),<br>    <span class="hljs-attribute">nn</span>.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>    <span class="hljs-attribute">nn</span>.Dropout(p=<span class="hljs-number">0</span>.<span class="hljs-number">5</span>),<br>    <span class="hljs-comment"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span><br>    <span class="hljs-attribute">nn</span>.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>))<br><br><span class="hljs-attribute">X</span> = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br><span class="hljs-attribute">for</span> layer in net:<br>    <span class="hljs-attribute">X</span>=layer(X)<br>    <span class="hljs-attribute">print</span>(layer.__class__.__name__,&#x27;output shape:\t&#x27;,X.shape)<br>    <br><span class="hljs-attribute">batch_size</span> = <span class="hljs-number">128</span><br><span class="hljs-attribute">train_iter</span>, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><br><span class="hljs-attribute">lr</span>, num_epochs = <span class="hljs-number">0</span>.<span class="hljs-number">01</span>, <span class="hljs-number">10</span><br><span class="hljs-attribute">d2l</span>.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br></code></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集。</li><li>今天，AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步。</li><li>尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受深度学习这一概念，并应用其出色的实验结果。这也是由于缺乏有效的计算工具。</li><li>Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤。</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习11：LeNet</title>
    <link href="/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A011%EF%BC%9ALeNet/"/>
    <url>/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A011%EF%BC%9ALeNet/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习11：LeNet"><a href="#动手学深度学习11：LeNet" class="headerlink" title="动手学深度学习11：LeNet"></a>动手学深度学习11：LeNet</h2><h3 id="LeNet结构"><a href="#LeNet结构" class="headerlink" title="LeNet结构"></a>LeNet结构</h3><p>总体来看，(<strong>LeNet（LeNet-5）由两个部分组成：</strong>)</p><ul><li>卷积编码器：由两个卷积层组成;</li><li>全连接层密集块：由三个全连接层组成。</li></ul><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103231418291.png" alt="LeNet结构"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103231907258.png" alt="LeNet每层输出"></p><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>net = nn.Sequential(<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>), nn.Sigmoid(), <span class="hljs-comment"># 输入通道1，输出通道6</span><br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">5</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Flatten(),<br>    nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br>   <br>X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>), dtype=torch.float32)<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape: \t&#x27;</span>,X.shape)<br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103232209678.png" alt="image-20230103232209678"></p><p>在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。第一个卷积层使用2个像素的填充，来补偿$5 \times 5$卷积核导致的特征减少。相反，第二个卷积层没有填充，因此高度和宽度都减少了4个像素。随着层叠的上升，通道的数量从输入时的1个，增加到第一个卷积层之后的6个，再到第二个卷积层之后的16个。同时，每个汇聚层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果分类数相匹配的输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型训练</span><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_accuracy_gpu</span>(<span class="hljs-params">net, data_iter, device=<span class="hljs-literal">None</span></span>): <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 设置为评估模式</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> device:<br>            device = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(net.parameters())).device<br>    <span class="hljs-comment"># 正确预测的数量，总预测的数量</span><br>    metric = d2l.Accumulator(<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(X, <span class="hljs-built_in">list</span>):<br>                <span class="hljs-comment"># BERT微调所需的（之后将介绍）</span><br>                X = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>            <span class="hljs-keyword">else</span>:<br>                X = X.to(device)<br>            y = y.to(device)<br>            metric.add(d2l.accuracy(net(X), y), y.numel())<br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch6</span>(<span class="hljs-params">net, train_iter, test_iter, num_epochs, lr, device</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用GPU训练模型(在第六章定义)&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 参数初始化</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear <span class="hljs-keyword">or</span> <span class="hljs-built_in">type</span>(m) == nn.Conv2d:<br>            nn.init.xavier_uniform_(m.weight)<br>    net.apply(init_weights)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;training on&#x27;</span>, device)<br>    net.to(device)<br>    optimizer = torch.optim.SGD(net.parameters(), lr=lr)<br>    loss = nn.CrossEntropyLoss()<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs],<br>                            legend=[<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>])<br>    timer, num_batches = d2l.Timer(), <span class="hljs-built_in">len</span>(train_iter)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-comment"># 训练损失之和，训练准确率之和，样本数</span><br>        metric = d2l.Accumulator(<span class="hljs-number">3</span>)<br>        net.train()<br>        <span class="hljs-keyword">for</span> i, (X, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            timer.start()<br>            optimizer.zero_grad()<br>            X, y = X.to(device), y.to(device)<br>            y_hat = net(X)<br>            l = loss(y_hat, y)<br>            l.backward()<br>            optimizer.step()<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                metric.add(l * X.shape[<span class="hljs-number">0</span>], d2l.accuracy(y_hat, y), X.shape[<span class="hljs-number">0</span>])<br>            timer.stop()<br>            train_l = metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]<br>            train_acc = metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]<br>            <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % (num_batches // <span class="hljs-number">5</span>) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> i == num_batches - <span class="hljs-number">1</span>:<br>                animator.add(epoch + (i + <span class="hljs-number">1</span>) / num_batches,<br>                             (train_l, train_acc, <span class="hljs-literal">None</span>))<br>        test_acc = evaluate_accuracy_gpu(net, test_iter)<br>        animator.add(epoch + <span class="hljs-number">1</span>, (<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, test_acc))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;loss <span class="hljs-subst">&#123;train_l:<span class="hljs-number">.3</span>f&#125;</span>, train acc <span class="hljs-subst">&#123;train_acc:<span class="hljs-number">.3</span>f&#125;</span>, &#x27;</span><br>          <span class="hljs-string">f&#x27;test acc <span class="hljs-subst">&#123;test_acc:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;metric[<span class="hljs-number">2</span>] * num_epochs / timer.<span class="hljs-built_in">sum</span>():<span class="hljs-number">.1</span>f&#125;</span> examples/sec &#x27;</span><br>          <span class="hljs-string">f&#x27;on <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br><br>lr, num_epochs = <span class="hljs-number">0.9</span>, <span class="hljs-number">10</span><br>train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br></code></pre></td></tr></table></figure><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103232921767.png" alt="实验结果"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>卷积神经网络（CNN）是一类使用卷积层的网络。</li><li>在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。</li><li>为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。</li><li>在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。</li><li>LeNet是最早发布的卷积神经网络之一。</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习10：汇聚层（pooling）</title>
    <link href="/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A010%EF%BC%9A%E6%B1%87%E8%81%9A%E5%B1%82%EF%BC%88pooling%EF%BC%89/"/>
    <url>/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A010%EF%BC%9A%E6%B1%87%E8%81%9A%E5%B1%82%EF%BC%88pooling%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习10：汇聚层（pooling）"><a href="#动手学深度学习10：汇聚层（pooling）" class="headerlink" title="动手学深度学习10：汇聚层（pooling）"></a>动手学深度学习10：汇聚层（pooling）</h2><p>通常当我们处理图像时，我们希望逐渐降低隐藏表示的空间分辨率、聚集信息，这样随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野（输入）就越大。</p><p>而我们的机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”），所以我们最后一层的神经元应该对整个输入的全局敏感。通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层。</p><p>除此之外，汇聚层海可以降低卷积层对位置的敏感性，使得模型具有更好的鲁棒性。</p><h3 id="最大汇聚层和平均汇聚层"><a href="#最大汇聚层和平均汇聚层" class="headerlink" title="最大汇聚层和平均汇聚层"></a>最大汇聚层和平均汇聚层</h3><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103230015482.png" alt="image-20230103230015482"></p><p>汇聚窗口形状为$p \times q$的汇聚层称为$p \times q$汇聚层，汇聚操作称为$p \times q$汇聚。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pool2d</span>(<span class="hljs-params">X, pool_size, mode=<span class="hljs-string">&#x27;max&#x27;</span></span>):<br>    p_h, p_w = pool_size<br>    Y = torch.zeros((X.shape[<span class="hljs-number">0</span>] - p_h + <span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>] - p_w + <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">1</span>]):<br>            <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;max&#x27;</span>:<br>                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="hljs-built_in">max</span>()<br>            <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;avg&#x27;</span>:<br>                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()<br>    <span class="hljs-keyword">return</span> Y<br><br>X = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>]])<br><span class="hljs-built_in">print</span>(pool2d(X, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br><span class="hljs-built_in">print</span>(pool2d(X, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-string">&#x27;avg&#x27;</span>))<br><br></code></pre></td></tr></table></figure><p>与卷积层一样，汇聚层也可以改变输出形状。</p><p>默认情况下，(<strong>深度学习框架中的步幅与汇聚窗口的大小相同</strong>)。<br>因此，如果我们使用形状为<code>(3, 3)</code>的汇聚窗口，那么默认情况下，我们得到的步幅形状为<code>(3, 3)</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.arange(<span class="hljs-number">16</span>, dtype=torch.float32).reshape((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br><span class="hljs-comment"># tensor([[[[ 0.,  1.,  2.,  3.],</span><br><span class="hljs-comment">#           [ 4.,  5.,  6.,  7.],</span><br><span class="hljs-comment">#           [ 8.,  9., 10., 11.],</span><br><span class="hljs-comment">#           [12., 13., 14., 15.]]]])</span><br>pool2d = nn.MaxPool2d(<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=<span class="hljs-number">2</span>)<br>pool2d(X) <br><span class="hljs-comment"># tensor([[[[ 5.,  7.],</span><br><span class="hljs-comment">#           [13., 15.]]]])</span><br></code></pre></td></tr></table></figure><p>在处理多通道输入数据时，[<strong>汇聚层在每个输入通道上单独运算</strong>]，而不是像卷积层一样在通道上对输入进行汇总。<br>这意味着汇聚层的输出通道数与输入通道数相同。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>对于给定输入元素，最大汇聚层会输出该窗口内的最大值，平均汇聚层会输出该窗口内的平均值。</li><li>汇聚层的主要优点之一是减轻卷积层对位置的过度敏感。</li><li>我们可以指定汇聚层的填充和步幅。</li><li>使用最大汇聚层以及大于1的步幅，可减少空间维度（如高度和宽度）。</li><li>汇聚层的输出通道数与输入通道数相同。</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习09：多输入多输出通道</title>
    <link href="/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A009%EF%BC%9A%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93/"/>
    <url>/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A009%EF%BC%9A%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习09：多输入多输出通道"><a href="#动手学深度学习09：多输入多输出通道" class="headerlink" title="动手学深度学习09：多输入多输出通道"></a>动手学深度学习09：多输入多输出通道</h2><p>当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有$3\times h\times w$的形状。我们将这个大小为$3$的轴称为<em>通道</em>（channel）维度。</p><h3 id="多输入通道"><a href="#多输入通道" class="headerlink" title="多输入通道"></a>多输入通道</h3><p>当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。</p><p>当$c_i&gt;1$时，我们卷积核的每个输入通道将包含形状为$k_h\times k_w$的张量。将这些张量$c_i$连结在一起可以得到形状为$c_i\times k_h\times k_w$的卷积核。由于输入和卷积核都有$c_i$个通道，我们可以对每个通道输入的二维张量和卷积核的二维张量进行互相关运算，再对通道求和（将$c_i$的结果相加）得到二维张量。这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103224251820.png" alt="多通道卷积运算"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d_multi_in</span>(<span class="hljs-params">X, K</span>):<br>    <span class="hljs-comment"># 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(d2l.corr2d(x, k) <span class="hljs-keyword">for</span> x, k <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(X, K))<br><br>X = torch.tensor([[[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>]],<br>               [[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>], [<span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>, <span class="hljs-number">9.0</span>]]])<br>K = torch.tensor([[[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]], [[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>]]])<br><br><span class="hljs-built_in">print</span>(corr2d_multi_in(X, K))<br></code></pre></td></tr></table></figure><h3 id="多输出通道"><a href="#多输出通道" class="headerlink" title="多输出通道"></a>多输出通道</h3><p>直观地说，我们可以将每个通道看作对不同特征的响应。</p><p>用$c_i$和$c_o$分别表示输入和输出通道的数目，并让$k_h$和$k_w$为卷积核的高度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为$c_i\times k_h\times k_w$的卷积核张量，这样卷积核的形状是$c_o\times c_i\times k_h\times k_w$。在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>X = torch.tensor([[[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>]],<br>               [[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>], [<span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>, <span class="hljs-number">9.0</span>]]])<br>K = torch.tensor([[[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]], [[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>]]])<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d_multi_in_out</span>(<span class="hljs-params">X, K</span>):<br>    <span class="hljs-comment"># 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。</span><br>    <span class="hljs-comment"># 最后将所有结果都叠加在一起</span><br>    <span class="hljs-keyword">return</span> torch.stack([corr2d_multi_in(X, k) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> K], <span class="hljs-number">0</span>)<br><br>K = torch.stack((K, K + <span class="hljs-number">1</span>, K + <span class="hljs-number">2</span>), <span class="hljs-number">0</span>)<br>K.shape <span class="hljs-comment"># 3*2*2*2</span><br><br><span class="hljs-built_in">print</span>(corr2d_multi_in_out(X, K))<br></code></pre></td></tr></table></figure><h3 id="1×1-卷积层"><a href="#1×1-卷积层" class="headerlink" title="1×1 卷积层"></a>1×1 卷积层</h3><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103225024494.png" alt="image-20230103225024494"></p><p>我们可以将$1\times 1$卷积层看作在每个像素位置应用的全连接层，以$c_i$个输入值转换为$c_o$个输出值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d_multi_in_out_1x1</span>(<span class="hljs-params">X, K</span>):<br>    c_i, h, w = X.shape<br>    c_o = K.shape[<span class="hljs-number">0</span>]<br>    X = X.reshape((c_i, h * w))<br>    K = K.reshape((c_o, c_i))<br>    <span class="hljs-comment"># 全连接层中的矩阵乘法</span><br>    Y = torch.matmul(K, X)<br>    <span class="hljs-keyword">return</span> Y.reshape((c_o, h, w))<br></code></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>多输入多输出通道可以用来扩展卷积层的模型。</li><li>当以每像素为基础应用时，$1\times 1$卷积层相当于全连接层。</li><li>$1\times 1$卷积层通常用于调整网络层的通道数量和控制模型复杂</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习08：卷积中的填充与步幅</title>
    <link href="/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A008%EF%BC%9A%E5%8D%B7%E7%A7%AF%E4%B8%AD%E7%9A%84%E5%A1%AB%E5%85%85%E4%B8%8E%E6%AD%A5%E5%B9%85/"/>
    <url>/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A008%EF%BC%9A%E5%8D%B7%E7%A7%AF%E4%B8%AD%E7%9A%84%E5%A1%AB%E5%85%85%E4%B8%8E%E6%AD%A5%E5%B9%85/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习08：卷积中的填充与步幅"><a href="#动手学深度学习08：卷积中的填充与步幅" class="headerlink" title="动手学深度学习08：卷积中的填充与步幅"></a>动手学深度学习08：卷积中的填充与步幅</h2><p>一个240×240像素的图像，经过10层5×5的卷积后，将减少到200×200像素。</p><p>如此一来，原始图像的边界丢失了许多有用信息。而<em>填充</em>是解决此问题最有效的方法； </p><p>有时，我们可能希望大幅降低图像的宽度和高度。例如，如果我们发现原始的输入分辨率十分冗余。<em>步幅</em>则可以在这类情况下提供帮助。</p><h3 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h3><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103174147447.png" alt="image-20230103174147447"></p><p>通常，如果我们添加𝑝ℎ行填充（大约一半在顶部，一半在底部）和𝑝𝑤列填充（左侧大约一半，右侧一半），则输出形状将为<br>$$<br>(n_h-k_h+p_h+1)\times(n_w-k_w+p_w+1)<br>$$<br>在许多情况下，我们需要设置$p_h&#x3D;k_h-1$和$p_w&#x3D;k_w-1$，使输入和输出具有相同的高度和宽度。</p><h3 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h3><p>每次滑动元素的数量称为<em>步幅</em>（stride）</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103181024590.png" alt="image-20230103181024590"></p><p>通常，当垂直步幅为$s_h$、水平步幅为$s_w$时，输出形状为<br>$$<br>\lfloor(n_h-k_h+p_h+s_h)&#x2F;s_h\rfloor \times \lfloor(n_w-k_w+p_w+s_w)&#x2F;s_w\rfloor<br>$$<br>如果我们设置了$p_h&#x3D;k_h-1$和$p_w&#x3D;k_w-1$，则输出形状将简化为$\lfloor(n_h+s_h-1)&#x2F;s_h\rfloor \times \lfloor(n_w+s_w-1)&#x2F;s_w\rfloor$。<br>更进一步，如果输入的高度和宽度可以被垂直和水平步幅整除，则输出形状将为$(n_h&#x2F;s_h) \times (n_w&#x2F;s_w)$。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><br><span class="hljs-comment"># 为了方便起见，我们定义了一个计算卷积层的函数。</span><br><span class="hljs-comment"># 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">comp_conv2d</span>(<span class="hljs-params">conv2d, X</span>):<br>    <span class="hljs-comment"># 这里的（1，1）表示批量大小和通道数都是1</span><br>    X = X.reshape((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>) + X.shape)<br>    Y = conv2d(X)<br>    <span class="hljs-comment"># 省略前两个维度：批量大小和通道</span><br>    <span class="hljs-keyword">return</span> Y.reshape(Y.shape[<span class="hljs-number">2</span>:])<br><br><span class="hljs-comment"># 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列</span><br>conv2d = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>X = torch.rand(size=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><br><span class="hljs-comment"># 当卷积核的高度和宽度不同时，可以填充不同的高度和宽度</span><br>conv2d = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, kernel_size=(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>), padding=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><br>conv2d = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><br>conv2d = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), padding=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><br></code></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>填充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。</li><li>步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的1&#x2F;𝑛1&#x2F;n（𝑛n是一个大于11的整数）。</li><li>填充和步幅可用于有效地调整数据的维度。</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习07：从全连接层到卷积</title>
    <link href="/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A007%EF%BC%9A%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF/"/>
    <url>/2023/01/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A007%EF%BC%9A%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习07：从全连接层到卷积"><a href="#动手学深度学习07：从全连接层到卷积" class="headerlink" title="动手学深度学习07：从全连接层到卷积"></a>动手学深度学习07：从全连接层到卷积</h2><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>到目前为止，我们处理这类结构丰富的数据的方式还不够有效。 我们仅仅通过将图像数据展平成一维向量而忽略了每个图像的空间结构信息，再将数据送入一个全连接的多层感知机中</p><p><em>卷积神经网络</em>（convolutional neural network，CNN）是一类强大的、为处理图像数据而设计的神经网络。</p><p>多层感知机十分适合处理表格数据，其中行对应样本，列对应特征。</p><p>全连接层的参数量大，训练代价大。</p><p>设计适合于计算机视觉的神经网络架构</p><ul><li><em>平移不变性</em>（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。</li><li><em>局部性</em>（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。</li></ul><p><strong>小结</strong></p><ul><li>图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。</li><li>局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。</li><li>在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。</li><li>卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。</li><li>多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。</li></ul><h3 id="图像卷积"><a href="#图像卷积" class="headerlink" title="图像卷积"></a>图像卷积</h3><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103171120580.png" alt="卷积运算"></p><p>输出大小等于输入大小n_h \times n_w减去卷积核大小k_h \times k_w，即：</p><p>$$<br>(n_h-k_h+1) \times (n_w-k_w+1)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d</span>(<span class="hljs-params">X, K</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;计算二维卷积运算&quot;&quot;&quot;</span><br>    h, w = K.shape<br>    Y = torch.zeros((X.shape[<span class="hljs-number">0</span>] - h + <span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>] - w + <span class="hljs-number">1</span>)) <span class="hljs-comment"># 输出大小</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">1</span>]):<br>            Y[i, j] = (X[i:i + h, j:j + w] * K).<span class="hljs-built_in">sum</span>()<br>    <span class="hljs-keyword">return</span> Y<br><br>X = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>]])<br>K = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]])<br><span class="hljs-built_in">print</span>(corr2d(X, K))<br></code></pre></td></tr></table></figure><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Conv2</span>D(nn.<span class="hljs-title class_">Module</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, kernel_size</span>):<br>        <span class="hljs-variable language_">super</span>().__init__()<br>        <span class="hljs-comment"># 参数初始化</span><br>        <span class="hljs-variable language_">self</span>.weight = nn.<span class="hljs-title class_">Parameter</span>(torch.rand(kernel_size))<br>        <span class="hljs-variable language_">self</span>.bias = nn.<span class="hljs-title class_">Parameter</span>(torch.zeros(<span class="hljs-number">1</span>))<br>    <span class="hljs-comment"># 前向传播</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, x</span>):<br>        <span class="hljs-keyword">return</span> corr2d(x, <span class="hljs-variable language_">self</span>.weight) + <span class="hljs-variable language_">self</span>.bias<br></code></pre></td></tr></table></figure><h4 id="一个简单应用：检测目标的边缘"><a href="#一个简单应用：检测目标的边缘" class="headerlink" title="一个简单应用：检测目标的边缘"></a>一个简单应用：检测目标的边缘</h4><p><strong>检测图像中不同颜色的边缘</strong></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103171922989.png" alt="image-20230103171922989"></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">X</span> = torch.ones((<span class="hljs-number">6</span>, <span class="hljs-number">8</span>))<br><span class="hljs-attribute">X</span>[:, <span class="hljs-number">2</span>:<span class="hljs-number">6</span>] = <span class="hljs-number">0</span><br><span class="hljs-attribute">print</span>(X)<br><span class="hljs-attribute">K</span> = torch.tensor([[<span class="hljs-number">1</span>.<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>.<span class="hljs-number">0</span>]])<br><span class="hljs-attribute">Y</span> = corr2d(X, K)<br><span class="hljs-attribute">Y</span><br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230103172051446.png" alt="image-20230103172051446"></p><p>上面这个kernal只能检测垂直边缘，无法检测水平边缘</p><h3 id="学习卷积核"><a href="#学习卷积核" class="headerlink" title="学习卷积核"></a>学习卷积核</h3><p><strong>学习由<code>X</code>生成<code>Y</code>的卷积核</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核</span><br><span class="hljs-attribute">conv2d</span> = nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), bias=False)<br><br><span class="hljs-comment"># 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），</span><br><span class="hljs-comment"># 其中批量大小和通道数都为1</span><br><span class="hljs-attribute">X</span> = X.reshape((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>))<br><span class="hljs-attribute">Y</span> = Y.reshape((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>))<br><span class="hljs-attribute">lr</span> = <span class="hljs-number">3</span>e-<span class="hljs-number">2</span>  # 学习率<br><br><span class="hljs-attribute">for</span> i in range(<span class="hljs-number">10</span>):<br>    <span class="hljs-attribute">Y_hat</span> = conv2d(X)<br>    <span class="hljs-attribute">l</span> = (Y_hat - Y) ** <span class="hljs-number">2</span><br>    <span class="hljs-attribute">conv2d</span>.zero_grad()<br>    <span class="hljs-attribute">l</span>.sum().backward()<br>    <span class="hljs-comment"># 迭代卷积核</span><br>    <span class="hljs-attribute">conv2d</span>.weight.data[:] -= lr * conv2d.weight.grad<br>    <span class="hljs-attribute">if</span> (i + <span class="hljs-number">1</span>) % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-attribute">print</span>(f&#x27;epoch &#123;i+<span class="hljs-number">1</span>&#125;, loss &#123;l.sum():.<span class="hljs-number">3</span>f&#125;&#x27;)<br>        <br><span class="hljs-attribute">print</span>(conv2d.weight.data.reshape((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)))<br></code></pre></td></tr></table></figure><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。</li><li>我们可以设计一个卷积核来检测图像的边缘。</li><li>我们可以从数据中学习卷积核的参数。</li><li>学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。</li><li>当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习06：Kaggle实战：预测房价</title>
    <link href="/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A006%EF%BC%9AKaggle%E5%AE%9E%E6%88%98%EF%BC%9A%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/"/>
    <url>/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A006%EF%BC%9AKaggle%E5%AE%9E%E6%88%98%EF%BC%9A%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习06：Kaggle实战：预测房价"><a href="#动手学深度学习06：Kaggle实战：预测房价" class="headerlink" title="动手学深度学习06：Kaggle实战：预测房价"></a>动手学深度学习06：Kaggle实战：预测房价</h2><p>竞赛地址：<a href="https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques">https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques</a></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hashlib<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> tarfile<br><span class="hljs-keyword">import</span> zipfile<br><span class="hljs-keyword">import</span> requests<br><br><span class="hljs-comment">#@save</span><br>DATA_HUB = <span class="hljs-built_in">dict</span>()<br>DATA_URL = <span class="hljs-string">&#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">download</span>(<span class="hljs-params">name, cache_dir=os.path.join(<span class="hljs-params"><span class="hljs-string">&#x27;..&#x27;</span>, <span class="hljs-string">&#x27;data&#x27;</span></span>)</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">assert</span> name <span class="hljs-keyword">in</span> DATA_HUB, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;name&#125;</span> 不存在于 <span class="hljs-subst">&#123;DATA_HUB&#125;</span>&quot;</span><br>    url, sha1_hash = DATA_HUB[name]<br>    os.makedirs(cache_dir, exist_ok=<span class="hljs-literal">True</span>)<br>    fname = os.path.join(cache_dir, url.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">if</span> os.path.exists(fname):<br>        sha1 = hashlib.sha1()<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(fname, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>                data = f.read(<span class="hljs-number">1048576</span>)<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> data:<br>                    <span class="hljs-keyword">break</span><br>                sha1.update(data)<br>        <span class="hljs-keyword">if</span> sha1.hexdigest() == sha1_hash:<br>            <span class="hljs-keyword">return</span> fname  <span class="hljs-comment"># 命中缓存</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;正在从<span class="hljs-subst">&#123;url&#125;</span>下载<span class="hljs-subst">&#123;fname&#125;</span>...&#x27;</span>)<br>    r = requests.get(url, stream=<span class="hljs-literal">True</span>, verify=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(fname, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(r.content)<br>    <span class="hljs-keyword">return</span> fname<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">download_extract</span>(<span class="hljs-params">name, folder=<span class="hljs-literal">None</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;下载并解压zip/tar文件&quot;&quot;&quot;</span><br>    fname = download(name)<br>    base_dir = os.path.dirname(fname)<br>    data_dir, ext = os.path.splitext(fname)<br>    <span class="hljs-keyword">if</span> ext == <span class="hljs-string">&#x27;.zip&#x27;</span>:<br>        fp = zipfile.ZipFile(fname, <span class="hljs-string">&#x27;r&#x27;</span>)<br>    <span class="hljs-keyword">elif</span> ext <span class="hljs-keyword">in</span> (<span class="hljs-string">&#x27;.tar&#x27;</span>, <span class="hljs-string">&#x27;.gz&#x27;</span>):<br>        fp = tarfile.<span class="hljs-built_in">open</span>(fname, <span class="hljs-string">&#x27;r&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">assert</span> <span class="hljs-literal">False</span>, <span class="hljs-string">&#x27;只有zip/tar文件可以被解压缩&#x27;</span><br>    fp.extractall(base_dir)<br>    <span class="hljs-keyword">return</span> os.path.join(base_dir, folder) <span class="hljs-keyword">if</span> folder <span class="hljs-keyword">else</span> data_dir<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">download_all</span>():  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> DATA_HUB:<br>        download(name)<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>DATA_HUB[<span class="hljs-string">&#x27;kaggle_house_train&#x27;</span>] = (  <span class="hljs-comment">#@save</span><br>    DATA_URL + <span class="hljs-string">&#x27;kaggle_house_pred_train.csv&#x27;</span>,<br>    <span class="hljs-string">&#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&#x27;</span>)<br><br>DATA_HUB[<span class="hljs-string">&#x27;kaggle_house_test&#x27;</span>] = (  <span class="hljs-comment">#@save</span><br>    DATA_URL + <span class="hljs-string">&#x27;kaggle_house_pred_test.csv&#x27;</span>,<br>    <span class="hljs-string">&#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#x27;</span>)<br><br>train_data = pd.read_csv(download(<span class="hljs-string">&#x27;kaggle_house_train&#x27;</span>))<br>test_data = pd.read_csv(download(<span class="hljs-string">&#x27;kaggle_house_test&#x27;</span>))<br><br><span class="hljs-built_in">print</span>(train_data.shape) <span class="hljs-comment"># 1460, 81 1460个样本，每个样本81个特征</span><br><span class="hljs-built_in">print</span>(test_data.shape) <span class="hljs-comment"># 1458, 331</span><br><span class="hljs-built_in">print</span>(train_data.iloc[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>, [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, -<span class="hljs-number">3</span>, -<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>]])<br>all_features = pd.concat((train_data.iloc[:, <span class="hljs-number">1</span>:-<span class="hljs-number">1</span>], test_data.iloc[:, <span class="hljs-number">1</span>:])) <span class="hljs-comment"># 去除第一列</span><br><br><span class="hljs-comment"># 数据预处理</span><br><span class="hljs-comment"># 若无法获得测试数据，则可根据训练数据计算均值和标准差</span><br>numeric_features = all_features.dtypes[all_features.dtypes != <span class="hljs-string">&#x27;object&#x27;</span>].index<br>all_features[numeric_features] = all_features[numeric_features].apply(<br>    <span class="hljs-keyword">lambda</span> x: (x - x.mean()) / (x.std()))<br><span class="hljs-comment"># 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0</span><br>all_features[numeric_features] = all_features[numeric_features].fillna(<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 处理离散值</span><br><span class="hljs-comment"># “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征</span><br>all_features = pd.get_dummies(all_features, dummy_na=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(all_features.shape)<br><br><span class="hljs-comment"># 从pandos格式中提取NumPy格式，并将其转换为张量表示用于训练</span><br>n_train = train_data.shape[<span class="hljs-number">0</span>]<br>train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)<br>test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)<br>train_labels = torch.tensor(<br>    train_data.SalePrice.values.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), dtype=torch.float32)<br><br><span class="hljs-comment"># 训练</span><br>loss = nn.MSELoss()<br>in_features = train_features.shape[<span class="hljs-number">1</span>] <span class="hljs-comment"># 输入特征个数，及模型输入大小</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_net</span>():<br>    net = nn.Sequential(nn.Linear(in_features,<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">return</span> net<br><br><span class="hljs-comment"># 误差评价方法，用价格预测的对数来衡量差异</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">log_rmse</span>(<span class="hljs-params">net, features, labels</span>):<br>    <span class="hljs-comment"># 为了在取对数时进一步稳定该值，将小于1的值设置为1</span><br>    clipped_preds = torch.clamp(net(features), <span class="hljs-number">1</span>, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>))<br>    rmse = torch.sqrt(loss(torch.log(clipped_preds),<br>                           torch.log(labels)))<br>    <span class="hljs-keyword">return</span> rmse.item()<br><br><span class="hljs-comment"># 我们的训练函数将借助Adam优化器，它对初始学习率不那么敏感</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, train_features, train_labels, test_features, test_labels,</span><br><span class="hljs-params">          num_epochs, learning_rate, weight_decay, batch_size</span>):<br>    train_ls, test_ls = [], []<br>    train_iter = d2l.load_array((train_features, train_labels), batch_size)<br>    <span class="hljs-comment"># 这里使用的是Adam优化算法</span><br>    optimizer = torch.optim.Adam(net.parameters(),<br>                                 lr = learning_rate,<br>                                 weight_decay = weight_decay)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            optimizer.zero_grad()<br>            l = loss(net(X), y)<br>            l.backward()<br>            optimizer.step()<br>        train_ls.append(log_rmse(net, train_features, train_labels))<br>        <span class="hljs-keyword">if</span> test_labels <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            test_ls.append(log_rmse(net, test_features, test_labels))<br>    <span class="hljs-keyword">return</span> train_ls, test_ls<br><br><span class="hljs-comment"># k折交叉验证</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_k_fold_data</span>(<span class="hljs-params">k, i, X, y</span>):<br>    <span class="hljs-keyword">assert</span> k &gt; <span class="hljs-number">1</span><br>    fold_size = X.shape[<span class="hljs-number">0</span>] // k<br>    X_train, y_train = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        idx = <span class="hljs-built_in">slice</span>(j * fold_size, (j + <span class="hljs-number">1</span>) * fold_size)<br>        X_part, y_part = X[idx, :], y[idx]<br>        <span class="hljs-keyword">if</span> j == i:<br>            X_valid, y_valid = X_part, y_part<br>        <span class="hljs-keyword">elif</span> X_train <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            X_train, y_train = X_part, y_part<br>        <span class="hljs-keyword">else</span>:<br>            X_train = torch.cat([X_train, X_part], <span class="hljs-number">0</span>)<br>            y_train = torch.cat([y_train, y_part], <span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> X_train, y_train, X_valid, y_valid<br><br><span class="hljs-comment"># 在 𝐾 折交叉验证中训练 𝐾 次后，[返回训练和验证误差的平均值]</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">k_fold</span>(<span class="hljs-params">k, X_train, y_train, num_epochs, learning_rate, weight_decay,</span><br><span class="hljs-params">           batch_size</span>):<br>    train_l_sum, valid_l_sum = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        data = get_k_fold_data(k, i, X_train, y_train)<br>        net = get_net()<br>        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,<br>                                   weight_decay, batch_size)<br>        train_l_sum += train_ls[-<span class="hljs-number">1</span>]<br>        valid_l_sum += valid_ls[-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>            d2l.plot(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_epochs + <span class="hljs-number">1</span>)), [train_ls, valid_ls],<br>                     xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, ylabel=<span class="hljs-string">&#x27;rmse&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs],<br>                     legend=[<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;valid&#x27;</span>], yscale=<span class="hljs-string">&#x27;log&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;折<span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span>，训练log rmse<span class="hljs-subst">&#123;<span class="hljs-built_in">float</span>(train_ls[-<span class="hljs-number">1</span>]):f&#125;</span>, &#x27;</span><br>              <span class="hljs-string">f&#x27;验证log rmse<span class="hljs-subst">&#123;<span class="hljs-built_in">float</span>(valid_ls[-<span class="hljs-number">1</span>]):f&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">return</span> train_l_sum / k, valid_l_sum / k<br><br><span class="hljs-comment"># 超参数设定，开始训练</span><br>k, num_epochs, lr, weight_decay, batch_size = <span class="hljs-number">5</span>, <span class="hljs-number">100</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>, <span class="hljs-number">64</span><br>train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,<br>                          weight_decay, batch_size)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;k&#125;</span>-折验证: 平均训练log rmse: <span class="hljs-subst">&#123;<span class="hljs-built_in">float</span>(train_l):f&#125;</span>, &#x27;</span><br>      <span class="hljs-string">f&#x27;平均验证log rmse: <span class="hljs-subst">&#123;<span class="hljs-built_in">float</span>(valid_l):f&#125;</span>&#x27;</span>)<br>    <br><span class="hljs-comment"># 提交kaggle 预测</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_and_pred</span>(<span class="hljs-params">train_features, test_features, train_labels, test_data,</span><br><span class="hljs-params">                   num_epochs, lr, weight_decay, batch_size</span>):<br>    net = get_net()<br>    train_ls, _ = train(net, train_features, train_labels, <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>,<br>                        num_epochs, lr, weight_decay, batch_size)<br>    d2l.plot(np.arange(<span class="hljs-number">1</span>, num_epochs + <span class="hljs-number">1</span>), [train_ls], xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>,<br>             ylabel=<span class="hljs-string">&#x27;log rmse&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs], yscale=<span class="hljs-string">&#x27;log&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;训练log rmse：<span class="hljs-subst">&#123;<span class="hljs-built_in">float</span>(train_ls[-<span class="hljs-number">1</span>]):f&#125;</span>&#x27;</span>)<br>    <span class="hljs-comment"># 将网络应用于测试集。</span><br>    preds = net(test_features).detach().numpy()<br>    <span class="hljs-comment"># 将其重新格式化以导出到Kaggle</span><br>    test_data[<span class="hljs-string">&#x27;SalePrice&#x27;</span>] = pd.Series(preds.reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])<br>    submission = pd.concat([test_data[<span class="hljs-string">&#x27;Id&#x27;</span>], test_data[<span class="hljs-string">&#x27;SalePrice&#x27;</span>]], axis=<span class="hljs-number">1</span>)<br>    submission.to_csv(<span class="hljs-string">&#x27;submission.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br><br>train_and_pred(train_features, test_features, train_labels, test_data,<br>               num_epochs, lr, weight_decay, batch_size)<br></code></pre></td></tr></table></figure><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102223953594.png" alt="实验结果"></p>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>Kaggle</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习05：正则化技术</title>
    <link href="/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A005%EF%BC%9A%E6%AD%A3%E5%88%99%E5%8C%96%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A005%EF%BC%9A%E6%AD%A3%E5%88%99%E5%8C%96%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习05：正则化技术"><a href="#动手学深度学习05：正则化技术" class="headerlink" title="动手学深度学习05：正则化技术"></a>动手学深度学习05：正则化技术</h2><p>我们总是可以通过去收集更多的训练数据来缓解过拟合。 但这可能成本很高，耗时颇多，或者完全超出我们的控制，因而在短期内不可能做到。 假设我们已经拥有尽可能多的高质量数据，我们便可以将重点放在正则化技术上。</p><h3 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h3><p><em>权重衰减</em>（weight decay）是最广泛使用的正则化的技术之一， 它通常也被称为𝐿2<em>正则化</em><br>$$<br>L(\mathbf{w}, b) &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2<br>$$</p><p>$$<br>L(\mathbf{w}, b) + \frac{\lambda}{2} |\mathbf{w}|^2<br>$$</p><p>$$<br>\begin{aligned}<br>\mathbf{w} &amp; \leftarrow \left(1- \eta\lambda \right) \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right).<br>\end{aligned}<br>$$</p><h4 id="从零实现"><a href="#从零实现" class="headerlink" title="从零实现"></a>从零实现</h4><p>我们选择标签是关于输入的线性函数。 标签同时被均值为0，标准差为0.01高斯噪声破坏。 为了使过拟合的效果更加明显，我们可以将问题的维数增加到𝑑&#x3D;200， 并使用一个只包含20个样本的小训练集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment"># 生成数据</span><br>n_train, n_test, num_inputs, batch_size = <span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">200</span>, <span class="hljs-number">10</span><br>true_w, true_b = torch.ones((num_inputs, <span class="hljs-number">1</span>)) * <span class="hljs-number">0.01</span>, <span class="hljs-number">0.05</span><br>train_data = d2l.synthetic_data(true_w, true_b, n_train)<br>train_iter = d2l.load_array(train_data, batch_size)<br>test_data = d2l.synthetic_data(true_w, true_b, n_test)<br>test_iter = d2l.load_array(test_data, batch_size, is_train=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 初始化模型参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_params</span>():<br>    w = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, size=(num_inputs, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>)<br>    b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> [w, b]<br><br><span class="hljs-comment"># 定义L2范数惩罚</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">l2_penalty</span>(<span class="hljs-params">w</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">sum</span>(w.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>)) / <span class="hljs-number">2</span><br><br><span class="hljs-comment"># 训练代码</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">lambd</span>):<br>    w, b = init_params()<br>    net, loss = <span class="hljs-keyword">lambda</span> X: d2l.linreg(X, w, b), d2l.squared_loss<br>    num_epochs, lr = <span class="hljs-number">150</span>, <span class="hljs-number">0.03</span><br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epochs&#x27;</span>, ylabel=<span class="hljs-string">&#x27;loss&#x27;</span>, yscale=<span class="hljs-string">&#x27;log&#x27;</span>,<br>                            xlim=[<span class="hljs-number">5</span>, num_epochs], legend=[<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            <span class="hljs-comment"># 增加了L2范数惩罚项，</span><br>            <span class="hljs-comment"># 广播机制使l2_penalty(w)成为一个长度为batch_size的向量</span><br>            l = loss(net(X), y) + lambd * l2_penalty(w)<br>            l.<span class="hljs-built_in">sum</span>().backward()<br>            d2l.sgd([w, b], lr, batch_size)<br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">5</span> == <span class="hljs-number">0</span>:<br>            animator.add(epoch + <span class="hljs-number">1</span>, (d2l.evaluate_loss(net, train_iter, loss),<br>                                     d2l.evaluate_loss(net, test_iter, loss)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w的L2范数是：&#x27;</span>, torch.norm(w).item())<br><br>train(lambd=<span class="hljs-number">0</span>)<br>train(lambd=<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102163654737.png" alt="未使用权重衰减"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102163724969.png" alt="使用了权重衰减"></p><h4 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h4><p>我们在实例化优化器时直接通过<code>weight_decay</code>指定weight decay超参数。 默认情况下，PyTorch同时衰减权重和偏移。 这里我们只为权重设置了<code>weight_decay</code>，所以偏置参数𝑏b不会衰减。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_concise</span>(<span class="hljs-params">wd</span>):<br>    net = nn.Sequential(nn.Linear(num_inputs, <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> net.parameters():<br>        param.data.normal_()<br>    loss = nn.MSELoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br>    num_epochs, lr = <span class="hljs-number">150</span>, <span class="hljs-number">0.03</span><br>    <span class="hljs-comment"># 偏置参数没有衰减</span><br>    trainer = torch.optim.SGD([<br>        &#123;<span class="hljs-string">&quot;params&quot;</span>:net[<span class="hljs-number">0</span>].weight,<span class="hljs-string">&#x27;weight_decay&#x27;</span>: wd&#125;,<br>        &#123;<span class="hljs-string">&quot;params&quot;</span>:net[<span class="hljs-number">0</span>].bias&#125;], lr=lr)<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epochs&#x27;</span>, ylabel=<span class="hljs-string">&#x27;loss&#x27;</span>, yscale=<span class="hljs-string">&#x27;log&#x27;</span>,<br>                            xlim=[<span class="hljs-number">5</span>, num_epochs], legend=[<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            trainer.zero_grad()<br>            l = loss(net(X), y)<br>            l.mean().backward()<br>            trainer.step()<br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">5</span> == <span class="hljs-number">0</span>:<br>            animator.add(epoch + <span class="hljs-number">1</span>,<br>                         (d2l.evaluate_loss(net, train_iter, loss),<br>                          d2l.evaluate_loss(net, test_iter, loss)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w的L2范数：&#x27;</span>, net[<span class="hljs-number">0</span>].weight.norm().item())<br>    <br>train_concise(<span class="hljs-number">0</span>)<br>train_concise(<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102164601893.png" alt="未使用权重衰减"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102164608785.png" alt="使用了权重衰减"></p><ul><li>正则化是处理过拟合的常用方法：在训练集的损失函数中加入惩罚项，以降低学习到的模型的复杂度。</li><li>保持模型简单的一个特别的选择是使用𝐿2惩罚的权重衰减。这会导致学习算法更新步骤中的权重衰减。</li><li>权重衰减功能在深度学习框架的优化器中提供。</li><li>在同一训练代码实现中，不同的参数集可以有不同的更新行为。</li></ul><h3 id="暂退法（Dropout）"><a href="#暂退法（Dropout）" class="headerlink" title="暂退法（Dropout）"></a>暂退法（Dropout）</h3><p>暂退法在前向传播过程中，计算每一内部层的同时注入噪声,，从表面上看是在训练过程中丢弃（drop out）一些神经元</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102165831805.png" alt="暂退法"></p><h4 id="从零实现-1"><a href="#从零实现-1" class="headerlink" title="从零实现"></a>从零实现</h4><p>要实现单层的暂退法函数， 我们从均匀分布𝑈[0,1]U[0,1]中抽取样本，样本数与这层神经网络的维度一致。 然后我们保留那些对应样本大于𝑝p的节点，把剩下的丢弃。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment"># 实现 dropout_layer 函数， 该函数以dropout的概率丢弃张量输入X中的元素</span><br><span class="hljs-comment"># 如上所述重新缩放剩余部分：将剩余部分除以1.0-dropout</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout_layer</span>(<span class="hljs-params">X, dropout</span>):<br>    <span class="hljs-keyword">assert</span> <span class="hljs-number">0</span> &lt;= dropout &lt;= <span class="hljs-number">1</span><br>    <span class="hljs-comment"># 在本情况中，所有元素都被丢弃</span><br>    <span class="hljs-keyword">if</span> dropout == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> torch.zeros_like(X)<br>    <span class="hljs-comment"># 在本情况中，所有元素都被保留</span><br>    <span class="hljs-keyword">if</span> dropout == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> X<br>    mask = (torch.rand(X.shape) &gt; dropout).<span class="hljs-built_in">float</span>()<br>    <span class="hljs-keyword">return</span> mask * X / (<span class="hljs-number">1.0</span> - dropout)<br><br><span class="hljs-comment"># 定义模型参数</span><br><span class="hljs-comment"># 将暂退法应用于每个隐藏层的输出（在激活函数之后）</span><br><span class="hljs-comment"># 在靠近输入层的地方设置较低的暂退概率</span><br>dropout1, dropout2 = <span class="hljs-number">0.2</span>, <span class="hljs-number">0.5</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,</span><br><span class="hljs-params">                 is_training = <span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.num_inputs = num_inputs<br>        self.training = is_training<br>        self.lin1 = nn.Linear(num_inputs, num_hiddens1)<br>        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)<br>        self.lin3 = nn.Linear(num_hiddens2, num_outputs)<br>        self.relu = nn.ReLU()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        H1 = self.relu(self.lin1(X.reshape((-<span class="hljs-number">1</span>, self.num_inputs))))<br>        <span class="hljs-comment"># 只有在训练模型时才使用dropout</span><br>        <span class="hljs-keyword">if</span> self.training == <span class="hljs-literal">True</span>:<br>            <span class="hljs-comment"># 在第一个全连接层之后添加一个dropout层</span><br>            H1 = dropout_layer(H1, dropout1)<br>        H2 = self.relu(self.lin2(H1))<br>        <span class="hljs-keyword">if</span> self.training == <span class="hljs-literal">True</span>:<br>            <span class="hljs-comment"># 在第二个全连接层之后添加一个dropout层</span><br>            H2 = dropout_layer(H2, dropout2)<br>        out = self.lin3(H2)<br>        <span class="hljs-keyword">return</span> out<br><br>num_inputs, num_outputs, num_hiddens1, num_hiddens2 = <span class="hljs-number">784</span>, <span class="hljs-number">10</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span><br><br>net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)<br><br>num_epochs, lr, batch_size = <span class="hljs-number">10</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">256</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>trainer = torch.optim.SGD(net.parameters(), lr=lr)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102172916811.png" alt="image-20230102172916811"></p><h4 id="简洁实现-1"><a href="#简洁实现-1" class="headerlink" title="简洁实现"></a>简洁实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">net = nn.Sequential(nn.Flatten(),<br>        nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">256</span>),<br>        nn.ReLU(),<br>        <span class="hljs-comment"># 在第一个全连接层之后添加一个dropout层</span><br>        nn.Dropout(dropout1),<br>        nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>),<br>        nn.ReLU(),<br>        <span class="hljs-comment"># 在第二个全连接层之后添加一个dropout层</span><br>        nn.Dropout(dropout2),<br>        nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br><br>net.apply(init_weights);<br>trainer = torch.optim.SGD(net.parameters(), lr=lr)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102173206639.png" alt="image-20230102173206639"></p><ul><li>暂退法在前向传播过程中，计算每一内部层的同时丢弃一些神经元。</li><li>暂退法可以避免过拟合，它通常与控制权重向量的维数和大小结合使用的。</li><li>暂退法将活性值ℎ替换为具有期望值ℎ的随机变量。</li><li>暂退法仅在训练期间使用。</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习04：过拟合与欠拟合</title>
    <link href="/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A004%EF%BC%9A%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88/"/>
    <url>/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A004%EF%BC%9A%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习04：过拟合与欠拟合"><a href="#动手学深度学习04：过拟合与欠拟合" class="headerlink" title="动手学深度学习04：过拟合与欠拟合"></a>动手学深度学习04：过拟合与欠拟合</h2><p>将模型在训练数据上拟合的比在潜在分布中更接近的现象称为<em>过拟合</em>（overfitting）， 用于对抗过拟合的技术称为<em>正则化</em>（regularization）。</p><p>在实验中调整模型架构或超参数时会发现： 如果有足够多的神经元、层数和训练迭代周期， 模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。</p><h3 id="训练误差与泛化误差"><a href="#训练误差与泛化误差" class="headerlink" title="训练误差与泛化误差"></a>训练误差与泛化误差</h3><p><em>训练误差</em>（training error）是指， 模型在训练数据集上计算得到的误差。 </p><p><em>泛化误差</em>（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</p><p>当我们有简单的模型和大量的数据时，我们期望泛化误差与训练误差相近。</p><p>当我们有更复杂的模型和更少的样本时，我们预计训练误差会下降，但泛化误差会增大。</p><p>几个倾向于影响模型泛化的因素</p><ul><li>可调整参数的数量。当可调整参数的数量（有时称为<em>自由度</em>）很大时，模型往往更容易过拟合</li><li>参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合</li><li>训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活(flexible)的模型</li></ul><h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p><strong>验证集</strong></p><p>原则上，在我们确定所有的超参数之前，我们不希望用到测试集。</p><p>如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险，那就麻烦大了。 如果我们过拟合了训练数据，还可以在测试数据上的评估来判断过拟合。 但是如果我们过拟合了测试数据，我们又该怎么知道呢？</p><p>因此，我们决不能依靠测试数据进行模型选择。 然而，我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。</p><p>解决此问题的常见做法是将我们的数据分成三份， 除了训练和测试数据集之外，还增加一个<em>验证数据集</em>（validation dataset）， 也叫<em>验证集</em>（validation set）。</p><p><strong>𝐾折交叉验证</strong></p><p>原始训练数据被分成𝐾个不重叠的子集。 然后执行𝐾K次模型训练和验证，每次在𝐾−1个子集上进行训练， 并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。 最后，通过对𝐾次实验的结果取平均来估计训练和验证误差。</p><h3 id="过拟合与欠拟合"><a href="#过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合</h3><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102161357715.png" alt="过拟合与欠拟合"></p><p>训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合。 随着训练数据量的增加，泛化误差通常会减小。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差。</li><li>由于不能基于训练误差来估计泛化误差，因此简单地最小化训练误差并不一定意味着泛化误差的减小。机器学习模型需要注意防止过拟合，即防止泛化误差过大。</li><li>验证集可以用于模型选择，但不能过于随意地使用它。</li><li>我们应该选择一个复杂度适当的模型，避免使用数量不足的训练样本</li></ul>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习03：多层感知机</title>
    <link href="/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A003%EF%BC%9A%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    <url>/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A003%EF%BC%9A%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习03：多层感知机"><a href="#动手学深度学习03：多层感知机" class="headerlink" title="动手学深度学习03：多层感知机"></a>动手学深度学习03：多层感知机</h2><h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h3><p>我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制， 使其能处理更普遍的函数关系类型。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102151514851.png" alt="多层感知机"></p><p>这个多层感知机有4个输入，3个输出，其隐藏层包含5个隐藏单元，这个多层感知机中的层数为2。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>目的：引入非线性，使神经网络可以拟合任意的曲线（参考李宏毅机器学习教程）</p><p>有了激活函数，就不可能再将我们的多层感知机退化成线性模型</p><h4 id="ReLu函数"><a href="#ReLu函数" class="headerlink" title="ReLu函数"></a>ReLu函数</h4><p>$$<br>\operatorname{ReLU}(x) &#x3D; \max(x, 0)<br>$$</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102152019118.png" alt="Relu函数图像"></p><p>使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。 这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题</p><h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p>$$<br>\operatorname{sigmoid}(x) &#x3D; \frac{1}{1 + \exp(-x)}<br>$$</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102152303175.png" alt="sigmoid函数图像"></p><h4 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h4><p>$$<br>\operatorname{tanh}(x) &#x3D; \frac{1 - \exp(-2x)}{1 + \exp(-2x)}<br>$$</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102152405661.png" alt="image-20230102152405661"></p><h3 id="从零实现"><a href="#从零实现" class="headerlink" title="从零实现"></a>从零实现</h3><p><strong>实现一个具有单隐藏层的多层感知机， 它包含256个隐藏单元</strong></p><p>通常，我们选择2的若干次幂作为层的宽度。 因为内存在硬件中的分配和寻址方式，这么做往往可以在计算上更高效</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;实现一个具有单隐藏层的多层感知机，包含256个隐藏单元&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># 参数初始化</span><br>num_inputs, num_outputs, num_hiddens = <span class="hljs-number">784</span>, <span class="hljs-number">10</span>, <span class="hljs-number">256</span><br><br>W1 = nn.Parameter(torch.randn(<br>    num_inputs, num_hiddens, requires_grad=<span class="hljs-literal">True</span>) * <span class="hljs-number">0.01</span>) <span class="hljs-comment"># randn初始化是正态(0, 1)分布</span><br>b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=<span class="hljs-literal">True</span>))<br>W2 = nn.Parameter(torch.randn(<br>    num_hiddens, num_outputs, requires_grad=<span class="hljs-literal">True</span>) * <span class="hljs-number">0.01</span>)<br>b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=<span class="hljs-literal">True</span>))<br><br>params = [W1, b1, W2, b2]<br><br><span class="hljs-comment"># 激活函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">X</span>):<br>    a = torch.zeros_like(X)<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(X, a)<br><br><span class="hljs-comment"># 模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">net</span>(<span class="hljs-params">X</span>):<br>    X = X.reshape((-<span class="hljs-number">1</span>, num_inputs)) <span class="hljs-comment"># 256*1*28*28 -&gt; 256*784</span><br>    H = relu(X@W1 + b1)  <span class="hljs-comment"># 这里“@”代表矩阵乘法</span><br>    <span class="hljs-keyword">return</span> (H@W2 + b2)<br><br><span class="hljs-comment"># 损失函数</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br><br><span class="hljs-comment"># 训练 与上一节中的训练过程相似 使用相同的函数进行训练</span><br>num_epochs, lr = <span class="hljs-number">10</span>, <span class="hljs-number">0.1</span><br>updater = torch.optim.SGD(params, lr=lr)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)<br>d2l.predict_ch3(net, test_iter)<br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102154040798.png" alt="训练结果"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102154059506.png" alt="测试结果"></p><p>手动实现一个简单的多层感知机是很容易的。然而如果有大量的层，从零开始实现多层感知机会变得很麻烦（例如，要命名和记录模型的参数）。</p><h3 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h3><p><strong>通过高级API更简洁地实现多层感知机</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment"># 定义模型</span><br>net = nn.Sequential(nn.Flatten(),<br>                    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">256</span>),<br>                    nn.ReLU(),<br>                    nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>))<br><br><span class="hljs-comment"># 参数初始化</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br><br>net.apply(init_weights);<br><br>batch_size, lr, num_epochs = <span class="hljs-number">256</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">10</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br>trainer = torch.optim.SGD(net.parameters(), lr=lr)<br><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102154641229.png" alt="训练结果"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20230102154736816.png" alt="测试结果"></p>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习02：softmax回归的从零实现与简洁实现</title>
    <link href="/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A002%EF%BC%9Asoftmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0%E4%B8%8E%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/"/>
    <url>/2023/01/02/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A002%EF%BC%9Asoftmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0%E4%B8%8E%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习02：softmax回归的从零实现与简洁实现"><a href="#动手学深度学习02：softmax回归的从零实现与简洁实现" class="headerlink" title="动手学深度学习02：softmax回归的从零实现与简洁实现"></a>动手学深度学习02：softmax回归的从零实现与简洁实现</h2><p>参考：李沐 《动手学深度学习》 <a href="http://zh.d2l.ai/">http://zh.d2l.ai/</a></p><h3 id="从零实现"><a href="#从零实现" class="headerlink" title="从零实现"></a>从零实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> IPython <span class="hljs-keyword">import</span> display<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloader_workers</span>():  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用2个进程来读取数据&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data_fashion_mnist</span>(<span class="hljs-params">batch_size, resize=<span class="hljs-literal">None</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;下载Fashion-MNIST数据集，然后将其加载到内存中&quot;&quot;&quot;</span><br>    trans = [transforms.ToTensor()]<br>    <span class="hljs-keyword">if</span> resize:<br>        trans.insert(<span class="hljs-number">0</span>, transforms.Resize(resize))<br>    trans = transforms.Compose(trans)<br>    mnist_train = torchvision.datasets.FashionMNIST(<br>        root=<span class="hljs-string">&quot;./data&quot;</span>, train=<span class="hljs-literal">True</span>, transform=trans, download=<span class="hljs-literal">True</span>)<br>    mnist_test = torchvision.datasets.FashionMNIST(<br>        root=<span class="hljs-string">&quot;./data&quot;</span>, train=<span class="hljs-literal">False</span>, transform=trans, download=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> (data.DataLoader(mnist_train, batch_size, shuffle=<span class="hljs-literal">True</span>,<br>                            num_workers=get_dataloader_workers()),<br>            data.DataLoader(mnist_test, batch_size, shuffle=<span class="hljs-literal">False</span>,<br>                            num_workers=get_dataloader_workers()))<br><br><span class="hljs-comment"># 定义一个load_data_fashion_mnist函数，用于获取和读取Fashion-MNIST数据集</span><br><span class="hljs-comment"># 这个函数返回训练集和验证集的数据迭代器。 </span><br><span class="hljs-comment"># 此外，这个函数还接受一个可选参数resize，用来将图像大小调整为另一种形状。</span><br><span class="hljs-comment"># d2l已经封装好了这个函数，可以直接d2l.load_data_fashion_mnist()调用</span><br><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = load_data_fashion_mnist(batch_size)<br><br><span class="hljs-comment"># 原始数据集都是28*28图像，这里需要拉平及784的向量</span><br><span class="hljs-comment"># 参数初始化</span><br>num_inputs = <span class="hljs-number">784</span><br>num_outputs = <span class="hljs-number">10</span><br><br>W = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.zeros(num_outputs, requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 定义softmax</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">X</span>):<br>    X_exp = torch.exp(X)<br>    partition = X_exp.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 对每一行求和</span><br>    <span class="hljs-keyword">return</span> X_exp / partition  <span class="hljs-comment"># 这里应用了广播机制</span><br><span class="hljs-comment"># 验证softmax的效果</span><br>X = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">5</span>))<br>X_prob = softmax(X)<br><span class="hljs-built_in">print</span>(X_prob)<br><span class="hljs-built_in">print</span>(X_prob.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>))<br><br><span class="hljs-comment"># 定义模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">net</span>(<span class="hljs-params">X</span>):<br>    <span class="hljs-keyword">return</span> softmax(torch.matmul(X.reshape((-<span class="hljs-number">1</span>, W.shape[<span class="hljs-number">0</span>])), W) + b) <span class="hljs-comment"># x 此时为 batchsize * 784</span><br><br><br><span class="hljs-comment"># 定义损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy</span>(<span class="hljs-params">y_hat, y</span>):<br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br><br><span class="hljs-comment"># 分类精度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">y_hat, y</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;计算预测正确的数量&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(y_hat.shape) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> y_hat.shape[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span>:<br>        y_hat = y_hat.argmax(axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 每一行中最大元素的索引</span><br>    cmp = y_hat.<span class="hljs-built_in">type</span>(y.dtype) == y<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(cmp.<span class="hljs-built_in">type</span>(y.dtype).<span class="hljs-built_in">sum</span>())<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_accuracy</span>(<span class="hljs-params">net, data_iter</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;计算在指定数据集上模型的精度&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, torch.nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 将模型设置为评估模式</span><br>    metric = Accumulator(<span class="hljs-number">2</span>)  <span class="hljs-comment"># 正确预测数、预测总数</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            metric.add(accuracy(net(X), y), y.numel()) <span class="hljs-comment"># 正确数与总数</span><br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br><span class="hljs-comment"># 累计器</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Accumulator</span>:  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;在n个变量上累加&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * n<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, *args</span>):<br>        self.data = [a + <span class="hljs-built_in">float</span>(b) <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.data, args)]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset</span>(<span class="hljs-params">self</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * <span class="hljs-built_in">len</span>(self.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> self.data[idx]<br><br><span class="hljs-comment"># 训练</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_epoch_ch3</span>(<span class="hljs-params">net, train_iter, loss, updater</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;训练模型一个迭代周期（定义见第3章）&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 将模型设置为训练模式</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, torch.nn.Module):<br>        net.train()<br>    <span class="hljs-comment"># 训练损失总和、训练准确的总和、样本数</span><br>    metric = Accumulator(<span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-comment"># 计算梯度并更新参数</span><br>        y_hat = net(X)<br>        l = loss(y_hat, y)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(updater, torch.optim.Optimizer):<br>            <span class="hljs-comment"># 使用PyTorch内置的优化器和损失函数</span><br>            updater.zero_grad()<br>            l.mean().backward()<br>            updater.step()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 使用定制的优化器和损失函数</span><br>            l.<span class="hljs-built_in">sum</span>().backward()<br>            updater(X.shape[<span class="hljs-number">0</span>])<br>        metric.add(<span class="hljs-built_in">float</span>(l.<span class="hljs-built_in">sum</span>()), accuracy(y_hat, y), y.numel())<br>    <span class="hljs-comment"># 返回训练损失和训练精度</span><br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>], metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch3</span>(<span class="hljs-params">net, train_iter, test_iter, loss, num_epochs, updater</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;训练模型（定义见第3章）&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)<br>        test_acc = evaluate_accuracy(net, test_iter)<br>    train_loss, train_acc = train_metrics<br>    <span class="hljs-keyword">assert</span> train_loss &lt; <span class="hljs-number">0.5</span>, train_loss<br>    <span class="hljs-keyword">assert</span> train_acc &lt;= <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> train_acc &gt; <span class="hljs-number">0.7</span>, train_acc<br>    <span class="hljs-keyword">assert</span> test_acc &lt;= <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> test_acc &gt; <span class="hljs-number">0.7</span>, test_acc<br><br>lr = <span class="hljs-number">0.1</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">updater</span>(<span class="hljs-params">batch_size</span>):<br>    <span class="hljs-keyword">return</span> d2l.sgd([W, b], lr, batch_size)<br><br>num_epochs = <span class="hljs-number">10</span><br>train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_ch3</span>(<span class="hljs-params">net, test_iter, n=<span class="hljs-number">6</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;预测标签（定义见第3章）&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>        <span class="hljs-keyword">break</span><br>    <span class="hljs-comment"># trues = d2l.get_fashion_mnist_labels(y)</span><br>    <span class="hljs-comment"># preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))</span><br>    <span class="hljs-comment"># titles = [true +&#x27;\n&#x27; + pred for true, pred in zip(trues, preds)]</span><br>    <span class="hljs-comment"># d2l.show_images(</span><br>    <span class="hljs-comment">#     X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])</span><br>    <span class="hljs-built_in">print</span>(y)<br>    <span class="hljs-built_in">print</span>(net(X).argmax(axis=<span class="hljs-number">1</span>))<br><br>predict_ch3(net, test_iter)<br></code></pre></td></tr></table></figure><h3 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br><br><span class="hljs-comment"># PyTorch不会隐式地调整输入的形状。因此，</span><br><span class="hljs-comment"># 我们在线性层前定义了展平层（flatten），来调整网络输入的形状</span><br>net = nn.Sequential(nn.Flatten(), nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br><br>net.apply(init_weights)<br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br>trainer = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.1</span>)<br>num_epochs = <span class="hljs-number">10</span><br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习01：线性回归的从零实现与简洁实现</title>
    <link href="/2023/01/01/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A001%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0%E4%B8%8E%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/"/>
    <url>/2023/01/01/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A001%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0%E4%B8%8E%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习01：线性回归的从零实现与简洁实现"><a href="#动手学深度学习01：线性回归的从零实现与简洁实现" class="headerlink" title="动手学深度学习01：线性回归的从零实现与简洁实现"></a>动手学深度学习01：线性回归的从零实现与简洁实现</h2><p>参考：李沐 《动手学深度学习》 <a href="http://zh.d2l.ai/">http://zh.d2l.ai/</a></p><h3 id="从零实现"><a href="#从零实现" class="headerlink" title="从零实现"></a>从零实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">synthetic_data</span>(<span class="hljs-params">w, b, num_examples</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;生成y=Xw+b+噪声&quot;&quot;&quot;</span><br>    X = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (num_examples, <span class="hljs-built_in">len</span>(w)))<br>    y = torch.matmul(X, w) + b<br>    y += torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, y.shape)<br>    <span class="hljs-keyword">return</span> X, y.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br><br>true_w = torch.tensor([<span class="hljs-number">2</span>, -<span class="hljs-number">3.4</span>])<br>true_b = <span class="hljs-number">4.2</span><br>features, labels = synthetic_data(true_w, true_b, <span class="hljs-number">1000</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;features:&#x27;</span>, features[<span class="hljs-number">0</span>],<span class="hljs-string">&#x27;\nlabel:&#x27;</span>, labels[<span class="hljs-number">0</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_iter</span>(<span class="hljs-params">batch_size, features, labels</span>):<br>    num_examples = <span class="hljs-built_in">len</span>(features) <span class="hljs-comment"># 所有样本的个数</span><br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_examples)) <span class="hljs-comment"># 将样本随机打乱</span><br>    <span class="hljs-comment"># 这些样本是随机读取的，没有特定的顺序</span><br>    random.shuffle(indices)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_examples, batch_size):<br>        batch_indices = torch.tensor(<br>            indices[i: <span class="hljs-built_in">min</span>(i + batch_size, num_examples)])<br>        <span class="hljs-keyword">yield</span> features[batch_indices], labels[batch_indices]<br><br>batch_size = <span class="hljs-number">10</span><br><span class="hljs-comment"># 得到一组小批量的数据</span><br><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels):<br>    <span class="hljs-built_in">print</span>(X, <span class="hljs-string">&#x27;\n&#x27;</span>, y)<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-comment"># 初始化模型参数</span><br><br>w = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 均值为0，标准差为0.01</span><br>b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment">#  定义模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">linreg</span>(<span class="hljs-params">X, w, b</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;线性回归模型&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> torch.matmul(X, w) + b<br><br><span class="hljs-comment"># 定义损失函数</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">squared_loss</span>(<span class="hljs-params">y_hat, y</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;均方损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="hljs-number">2</span> / <span class="hljs-number">2</span> <span class="hljs-comment"># 将真实值的形状变成与预测值一样</span><br><br><span class="hljs-comment"># 定义参数优化算法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sgd</span>(<span class="hljs-params">params, lr, batch_size</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;小批量随机梯度下降&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad(): <span class="hljs-comment"># 更新的时候不需要进行梯度计算</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>            param -= lr * param.grad / batch_size<br>            param.grad.zero_() <span class="hljs-comment"># 梯度会累计，计算完梯度后清0</span><br><br><span class="hljs-comment"># 训练</span><br>lr = <span class="hljs-number">0.03</span><br>num_epochs = <span class="hljs-number">3</span><br>net = linreg<br>loss = squared_loss<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels):<br>        l = loss(net(X, w, b), y)  <span class="hljs-comment"># X和y的小批量损失</span><br>        <span class="hljs-comment"># 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，</span><br>        <span class="hljs-comment"># 并以此计算关于[w,b]的梯度</span><br>        l.<span class="hljs-built_in">sum</span>().backward()<br>        sgd([w, b], lr, batch_size)  <span class="hljs-comment"># 使用参数的梯度更新参数</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        train_l = loss(net(features, w, b), labels)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, loss <span class="hljs-subst">&#123;<span class="hljs-built_in">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)<br><br><br></code></pre></td></tr></table></figure><h3 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br>true_w = torch.tensor([<span class="hljs-number">2</span>, -<span class="hljs-number">3.4</span>])<br>true_b = <span class="hljs-number">4.2</span><br>features, labels = d2l.synthetic_data(true_w, true_b, <span class="hljs-number">1000</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_array</span>(<span class="hljs-params">data_arrays, batch_size, is_train=<span class="hljs-literal">True</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot;</span><br>    dataset = data.TensorDataset(*data_arrays)<br>    <span class="hljs-keyword">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train)<br><br>batch_size = <span class="hljs-number">10</span><br>data_iter = load_array((features, labels), batch_size)<br><br><span class="hljs-comment"># print(next(iter(data_iter)))</span><br><br>net = nn.Sequential(nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>)) <span class="hljs-comment"># 输入特征形状为 2，输出为标量 1</span><br><br><span class="hljs-comment"># 模型参数初始化</span><br>net[<span class="hljs-number">0</span>].weight.data.normal_(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)<br>net[<span class="hljs-number">0</span>].bias.data.fill_(<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 定义损失函数</span><br>loss = nn.MSELoss()<br><br><span class="hljs-comment"># 定义优化算法</span><br>trainer = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.03</span>)<br><br><span class="hljs-comment"># 训练</span><br>num_epochs = <span class="hljs-number">3</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>        l = loss(net(X) ,y)<br>        trainer.zero_grad() <span class="hljs-comment"># 计算梯度前将梯度归为0</span><br>        l.backward()<br>        trainer.step()<br>    l = loss(net(features), labels)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, loss <span class="hljs-subst">&#123;l:f&#125;</span>&#x27;</span>)<br><br>w = net[<span class="hljs-number">0</span>].weight.data<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w的估计误差：&#x27;</span>, true_w - w.reshape(true_w.shape))<br>b = net[<span class="hljs-number">0</span>].bias.data<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b的估计误差：&#x27;</span>, true_b - b)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动手学深度学习00：环境搭建</title>
    <link href="/2022/12/31/%E6%9D%8E%E6%B2%90%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <url>/2022/12/31/%E6%9D%8E%E6%B2%90%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="动手学深度学习00：环境搭建"><a href="#动手学深度学习00：环境搭建" class="headerlink" title="动手学深度学习00：环境搭建"></a>动手学深度学习00：环境搭建</h2><h4 id="1-环境"><a href="#1-环境" class="headerlink" title="1 环境"></a>1 环境</h4><p>我的环境是ubuntu 18.04，在腾讯云上买的轻量云服务器进行使用，没有GPU，前几章可以正常使用，后面用到GPU就不好使了。可以作为一个快速上手的过渡版本。</p><h4 id="2-搭建步骤"><a href="#2-搭建步骤" class="headerlink" title="2 搭建步骤"></a>2 搭建步骤</h4><h5 id="1-安装python-3-8"><a href="#1-安装python-3-8" class="headerlink" title="(1) 安装python 3.8"></a>(1) 安装python 3.8</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">sudo su<br>apt-<span class="hljs-built_in">get</span> update<br>apt-<span class="hljs-built_in">get</span> install python3.8<br></code></pre></td></tr></table></figure><p>如果之前已经安装了python3，可以直接跳到第二步</p><p>如果之前安装的是python2，需要修改一下软链接</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">rm <span class="hljs-regexp">/usr/</span>bin/python <br>ln -s <span class="hljs-regexp">/usr/</span>bin<span class="hljs-regexp">/python3.8 /u</span>sr<span class="hljs-regexp">/bin/</span>python<br></code></pre></td></tr></table></figure><p>输入python验证</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221230145226881.png" alt="image-20221230145226881"></p><h5 id="2-安装torch-torchvision-jupyter"><a href="#2-安装torch-torchvision-jupyter" class="headerlink" title="(2) 安装torch torchvision jupyter"></a>(2) 安装torch torchvision jupyter</h5><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> torch torchvision jupyter<br></code></pre></td></tr></table></figure><blockquote><p>torch库较大，安装较慢，大概需要五六分钟左右。如果下载速度太慢，可以尝试进行换源。我买的腾讯云服务器，默认使用的是腾讯源。也可以使用其他源，豆瓣源等。换源方法可以在网上参考卡博主博客。</p></blockquote><p>如果安装失败，尝试更新pip</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">python -m pip install <span class="hljs-comment">--upgrade pip</span><br></code></pre></td></tr></table></figure><h5 id="3-下载动手学深度学习jypyter记事本并解压"><a href="#3-下载动手学深度学习jypyter记事本并解压" class="headerlink" title="(3) 下载动手学深度学习jypyter记事本并解压"></a>(3) 下载动手学深度学习jypyter记事本并解压</h5><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">wget https://<span class="hljs-built_in">zh</span>-v2.d2l.ai/d2l-<span class="hljs-built_in">zh</span>.zip<br>unzip d2l.zip<br></code></pre></td></tr></table></figure><p>如果没有unzip，执行 <code>apt-get zip</code>安装即可</p><p>解压后有以下文件</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221230144525793.png" alt="image-20221230144525793"></p><h5 id="4-运行jupyter-记事本"><a href="#4-运行jupyter-记事本" class="headerlink" title="(4) 运行jupyter 记事本"></a>(4) 运行jupyter 记事本</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> pytorch<br>jupyter notebook<br></code></pre></td></tr></table></figure><p>如果遇到下面这个报错</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221230144454046.png" alt="image-20221230144454046"></p><p>原因是没有配置环境变量</p><p>终端运行<code>sudo vim ~/.bashrc</code></p><p>然后添加下面内容到末尾</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=~/.local/bin:$&#123;PATH&#125;<br></code></pre></td></tr></table></figure><p>保存~&#x2F;.bashrc文件后，并在终端输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> ~/.bashrc<br></code></pre></td></tr></table></figure><p>再输入 <code>jupyter notebook</code>即可运行</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221230144840509.png" alt="image-20221230144840509"></p>]]></content>
    
    
    <categories>
      
      <category>动手学深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mobisys22 Melon笔记</title>
    <link href="/2022/12/27/Mobisys22-Melon%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/12/27/Mobisys22-Melon%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="Mobisys22-Melon笔记"><a href="#Mobisys22-Melon笔记" class="headerlink" title="Mobisys22 Melon笔记"></a>Mobisys22 Melon笔记</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>设备上学习是一种很有前途的新兴隐私保护机器学习范式技术。然而，通过定量实验，&#x3D;&#x3D;我们发现商品移动设备由于本地内存容量有限，不能很好地支持足够大的批处理大小的最先进的DNN训练。&#x3D;&#x3D;为了填补这一空白，我们提出了Melon，这是一种内存友好的设备上学习框架，它使大批量训练任务超出物理内存容量。Melon明智地改进了现有的内存保存技术，以适应资源受限的移动设备，即重新计算和微批处理。Meon 进一步结合了新技术来处理高内存碎片和内存适应。Melon进一步结合了新的技术来处理高内存碎片和内存适应。我们在商用移动设备上使用各种典型的DNN模型实现和评估Melon。结果表明，在相同的内存预算下，Melon 可以实现高达 4.33× 的批量大小。给定相同的批量大小，Melon 平均实现了 1.89 倍（高达 4.01×）更高的训练吞吐量，并且与竞争替代方案相比节省了高达 49.43% 的能量。此外，Melon 在内存预算适应方面平均减少了 78.59% 的计算量。</p><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 <strong>Introduction</strong></h3><p>深度神经网络 (DNN) 是当今移动应用程序的关键组成部分，例如语音助手、增强现实等。大量工作探索了如何利用强大的硬件和各种优化将 DNN 的推理阶段带入移动设备。作为向前迈出的一步，设备上的学习正在成为直接在移动设备上执行模型训练的新范式，特别是实现强大的&#x3D;&#x3D;隐私保护和个性化&#x3D;&#x3D;。它已经成为高级学习技术(如联邦学习、分裂学习等[41,60,67])和应用(如输入法、虚拟助手等[1,2,44]的基础。然而，由于本地硬件资源的限制，我们很直观地会问，现代DNN的训练在移动设备上是否负担得起。</p><p>不幸的是，正如我们将在§2中定量显示的那样，即使是具有8GB内存的高端移动设备也无法支持足够大的批量DNN训练，这对于实现高精度和稳定收敛是至关重要的。换句话说，&#x3D;&#x3D;内存墙阻碍了训练性能&#x3D;&#x3D;。在联邦学习中，这种内存不足将被放大，因为低端设备将是端到端收敛的瓶颈。为此，我们的目标是通过内存优化技术打破内存墙。</p><h5 id="Prior-wisdom"><a href="#Prior-wisdom" class="headerlink" title="Prior wisdom"></a>Prior wisdom</h5><p>我们注意到，模型训练的内存优化多年来在云计算中得到了广泛的研究，但在移动设备中很少讨论。因此，我们的第一个直觉是调查最成熟的云端内存优化技术是否可以用于移动设备。令我们惊讶的是，我们在§3 中的定量实验表明，云端技术很难应用于移动设备</p><ol><li>交换[33,42,52,74]引入了严重的同步开销，因为移动soc缺乏像服务器gpu这样的高速I&#x2F;O链路(如PCIe)</li><li>训练时的压缩极大地损害了模型的准确性，尤其是在联合设置中</li></ol><h5 id="Our-design"><a href="#Our-design" class="headerlink" title="Our design"></a>Our design</h5><p>我们提出了Melon，这是第一个可以实际部署在移动设备上的内存优化DNN训练框架。Melon在内存预算(应用程序或操作系统指定的训练过程可用内存的大小)下限制了峰值内存使用。Melo在理想情况下，当内存预算是无限的，不会产生任何精度下降，并获得相当的性能。（训练吞吐量和能源消耗）</p><p>Melon是基于我们对利用两种潜在技术的洞察而明智地构建的，这两种技术在云上还没有得到很好的探索</p><ol><li>micro batch</li><li>recomputation</li></ol><p>微批处理最初是为分布式学习中的跨gpu并行而提出的，但很少用于减少数据中心的内存使用，因为它会影响硬件并行性。由于移动设备的硬件容量有限，这个缺点可以很好地缓解。另一个缺点是，如果模型包含批量归一化(BatchNormalization, BN)层，在批处理中引入跨样本依赖性，则微批处理不能保证数学等效性。因此，对于具有 BN 层的模型，Melon 利用重新计算。重新计算可以通过丢弃和重新计算中间张量来帮助节省内存，但与内存交换相比，由于计算开销，通常认为云上的效率较低。正如本文后面所演示的，通过我们的新设计和技术，重新计算的成本实际上是可以接受的设备上训练。</p><h5 id="Challenges-and-techniques"><a href="#Challenges-and-techniques" class="headerlink" title="Challenges and techniques"></a>Challenges and techniques</h5><p>对于给定的DNN, Melon自动生成执行计划，指导不同内存预算下的训练行为。每个执行计划都详细阐述了内存张量分配、微批处理大小和重新计算调度策略，以在指定的内存预算下实现最佳性能。值得注意的是，Melon并不是简单地建立在微批处理和重新计算的组合之上。相反，我们遇到了以下独特的挑战，并通过我们的新技术解决了它们。</p><ul><li>Lifetime-aware memory pool</li></ul><p>首先，我们在模型训练期间观察到大量的内存碎片。设备上训练框架通常维护一个大型内存池来管理权重和中间激活。然而，由于分配策略不同和各种内存访问模式 [6, 26 , 45 ]，池的内存空间连续变为小块。根据我们的测量，在DNN训练期间，这些现有内存池的浪费内存可以达到42%。为了处理内存碎片，Melon 使用特定于模型的用户空间内存池，该池结合了静态内存访问模式的知识（即，当需要张量以及它在模型训练期间需要多少内存或称为生命周期）它基于一项简单但关键的观察，即训练期间生成的数万个张量具有多样化的生命周期。一个张量在内存中保留的时间越长，它就越可能与其他张量产生“干扰”。因此，Moon 使用贪心算法在低内存地址放置长期张量，以更好地整合内存池。【俄罗斯方块】</p><ul><li>Memory-calibrated progressive recomputation</li></ul><p>内存校准渐进重新计算。为了将所提出的生命周期感知内存池与重新计算技术相结合，Melon面临着“鸡还是蛋”困境。内存池将所有张量的生命周期作为输入，并生成张量分配计划以及所需的内存池的总大小。但是，重新计算将池大小作为输入来做出决定，这可能会影响池的策略。单独优化它们中的每一个并简单地应用一个顶部会导致次优性能.因此，Moon 提出了一种通过校准内存池进行重新计算算法。按照执行顺序，当使用的内存大于预算时，Melon丢弃一个分配的张量，并校准那些生命周期与被丢弃的张量有“干扰”的张量的位置。当内存中不存在当前运算符所需的张量时，Moon 搜索要重新计算的所有源张量并为它们分配内存。分配是通过扩展“时间轴”来执行的，根据它们的生命周期将张量添加到池中。然后Melon以与前面提到的相同的方式校准池。</p><ul><li>On-the-fly memory budget adapting</li></ul><p>前两种技术仅适用于静态内存预算。然而，移动设备是多应用程序或多任务环境。因此，Melon应该支持动态内存预算。简单地中止当前的批训练会导致大量的计算资源浪费，例如几十秒。为了以较低的开销快速响应新的内存预算，Melon使用了一种动态内存适应机制。一旦有了新的预算，Melonfirst就加载新的执行计划，并扩大&#x2F;缩小内存池以满足内存预算。然后，它根据新计划重新计算应保存在内存中但尚未呈现的张量（由于新&#x2F;旧计划的差异或丢弃的内存空间）。然后Melon调整张量位置以适应新计划并继续训练。通过这种方式，Melon通过重用先前计算结果的一部分来减少切换开销，而不是从一开始就重新执行DNN。</p><h5 id="Implementation-and-evaluation"><a href="#Implementation-and-evaluation" class="headerlink" title="Implementation and evaluation"></a>Implementation and evaluation</h5><p>我们已经在我们将在第 5 节中展示的最先进的设备上训练库 MNN [26 ] 上完全实现了 Meon 和 4 个基线。决策阶段一次性在客户端运行，例如，当应用程序安装时，会给开发人员带来几乎零的编程工作。然后，我们在四种典型的DNN模型和四种商用Android设备上进行了广泛的实验。实验结果表明，与vanilla MNN相比，Melon足以支持更大批量(4.33×)的设备上训练，这比所有基线都要显著得多。如此大的批大小使得melon在一个端到端的学习任务中，训练作业的收敛速度加快了3.48×，收敛精度提高了2.2%。为了支持相同的大批量，与基准相比，melon降低了49.43%的能源消耗。此外，与重启机制相比，Melon节省了高达95.73%的内存预算切换开销。</p><h5 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h5><ul><li>我们彻底测量和探索有希望的内存优化对设备上训练的深刻影响。</li><li>我们设计并实现了第一个内存优化的设备上训练框架Melon，具有三种新技术，即生命周期感知内存池、内存校准渐进重新计算和动态内存适应</li><li>我们用具有代表性的DNN模型和商用移动设备评估Melon。结果证明了它的有效性。</li></ul><h3 id="2-MOTIVATION-AND-PRELIMINARIES"><a href="#2-MOTIVATION-AND-PRELIMINARIES" class="headerlink" title="2 MOTIVATION AND PRELIMINARIES"></a>2 MOTIVATION AND PRELIMINARIES</h3><p>在本节中，我们将简要介绍设备上的训练，并进行初步实验。</p><h4 id="2-1-On-Device-Training"><a href="#2-1-On-Device-Training" class="headerlink" title="2.1 On-Device Training"></a>2.1 On-Device Training</h4><p>设备上训练的能力是许多高级学习场景的基础，如联邦学习[41]和边缘设置下设备上的迁移学习。着公众对数据隐私的日益关注和GDPR[4]等相关法律颁布，这种需求不断增长。</p><p>设备上训练通常采用随机梯度下降 (SGD) [9]，其中训练时期可以分为一些小批量。每一批的训练都应该经历一个完整的数据流：前向传递来计算损失，后向传递以获得梯度，以及基于梯度的参数更新。与模型推理（即预测）阶段不同，中间张量一旦它们已经被下一层使用，训练阶段需要保留前向传递期间生成的输出，直到它们在后向传递期间使用。因此，训练比推理需要更多的内存。</p><h5 id="Breakdown"><a href="#Breakdown" class="headerlink" title="Breakdown"></a>Breakdown</h5><p>我们使用最先进的设备上训练库 MNN 对 DNN 训练期间的峰值内存占用进行了细分分析。结果如图1所示，我们将内存使用分为3类，即&#x3D;&#x3D;权重内存(存储参数)，激活内存(存储中间输出)和优化器内存(存储梯度)。&#x3D;&#x3D;</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221211818878.png" alt="图1:内存占用细分"></p><p>它表明，&#x3D;&#x3D;激活内存通常主导整体内存消耗，并与批处理大小成线性比例&#x3D;&#x3D;。这意味着我们要在设备上学习过程中优化这部分内存。</p><h4 id="2-2-The-Memory-Wall"><a href="#2-2-The-Memory-Wall" class="headerlink" title="2.2 The Memory Wall"></a>2.2 The Memory Wall</h4><p>在这里，一个直观但尚未探索的问题是:商用移动设备能否支持典型DNN模型的训练，以达到良好的精度?在实践中，机器学习界已经达成共识，&#x3D;&#x3D;大的批大小有助于稳定收敛方向&#x3D;&#x3D;。我们还对批量大小如何影响集中式（即单个 GPU 机器中的数据）和联邦设置（即假设数据以非 IID 方式分布在许多客户端上）中的模型收敛性进行了测量研究）。实验结果如表2所示。我们确认大尺寸需要确保良好的准确性和收敛速度。具体来说，对于联邦设置中批量大小为 128 的 MobileNetV2，训练过程在第 164 轮收敛，比批量大小为 32 的 MobileNetV2 快 45.73%。此外，测试精度高 3.94%。相同的观察结果可以在集中式设置中找到，&#x3D;&#x3D;其中使用更大的批量大小会导致 2% 的准确率或 39.02% 更快的收敛时间。&#x3D;&#x3D;</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221212605094.png" alt="图2:不同批量训练的收敛速度"></p><p>然而，使用&#x3D;&#x3D;更大批量大小训练模型需要更多的内存容量也就不足为奇了&#x3D;&#x3D;。在实践中，商品移动设备不能充分支持大批量训练，即内存瓶颈。表 1 总结了内存墙如何影响设备上的训练。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221212642249.png" alt="表1:内存墙在移动设备上的影响"></p><p>即使使用旗舰高端商品设备（Samsung 注意 10、8GB RAM），MNN 库只能支持 32 的批量大小，同时在集中式和联邦设置中导致更低的准确性和更多的训练轮次。</p><p>【？128轮的是怎么训练出来的】</p><h3 id="3-EXPLORING-EXISTING-TECHNIQUES"><a href="#3-EXPLORING-EXISTING-TECHNIQUES" class="headerlink" title="3 EXPLORING EXISTING TECHNIQUES"></a>3 EXPLORING EXISTING TECHNIQUES</h3><p>在本节中，我们首先检查最初为云设计的现有内存节省技术，并定量分析为什么这些技术不足以用于移动设备。然后我们探索新的设计空间，可能有助于节省训练内存消耗。</p><h5 id="Model-amp-gradients-compression"><a href="#Model-amp-gradients-compression" class="headerlink" title="Model &amp; gradients compression"></a>Model &amp; gradients compression</h5><p>量化[48,64]（打马赛克）被广泛采用，&#x3D;&#x3D;通过减少表示每个权重所需的比特数来压缩dnn。&#x3D;&#x3D;例如，8位和16位量化是压缩dnn最常见的解决方案，精度损失可以忽略不计[18,58]。在极端情况下，使用1位表示法已被证明是有效的[12,13,51]。然而，为了减少内存占用，低精度表示下的训练模型比推理更具挑战性，而且往往会导致模型精度的不可接受的下降。</p><p>计算和存储网络激活所需的内存远远超过存储模型本身所需的内存。两种可能的解决方案是将输入数据压缩到更小的尺寸，或者使模型“更窄”(例如，减少每个卷积的输出通道数量)。超过一定程度，这些技术中的每一种都必然导致准确性的损失——前者是因为它丢弃了数据中的信息，后者是因为它降低了模型的表达能力</p><p>【压缩带来精度下降】</p><p>我们意识到，基于fp32的训练和基于int8的训练之间的精度差距是无法通过先进的学习算法来消除的。最近的一项研究[78]提出了一种反向量化的损失感知补偿，但在CIFAR-10数据集上的精度下降高达7.9%。另一种最先进的基于整数的训练算法NITI[63]使用了离散参数更新方案，也显著降低了DNN的精度。更糟糕的是，在像FL这样的新兴学习模式中，这种准确性差距可能会被放大。我们在图3所示的初步实验中观察到了这种现象，其中我们比较了集中设置和联邦设置下NITI的收敛过程。它表明，与基于fp32的训练相比，NITI的准确性下降在联邦设置中更为明显。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221213714568.png" alt="图3:联邦学习的准确性损失被放大了"></p><h5 id="Host-device-memory-swapping"><a href="#Host-device-memory-swapping" class="headerlink" title="Host-device memory swapping"></a>Host-device memory swapping</h5><p>主机和设备间的内存交换。云gpu通常配备专用的内存卡，这些内存卡之间的数据移动<strong>非常快</strong>，例如PCIe 5.0的128GB&#x2F;s。鉴于主存通常比GPU内存更丰富，之前的工作[42,50,52,61]探索了在DNN训练中使用主存作为外部数据备份。智能交换机制可以减少GPU上的内存占用，同时具有边际的吞吐量损失，因为CPU&#x2F;GPU内存之间的I&#x2F;O可以与训练重叠，并且可以完全覆盖开销。</p><p>然而，与云相比，交换不适用于移动设备，移动设备通常使用所有处理器的集成内存芯片。因此，交换只能在设备上的主内存和磁盘之间执行，其中带宽非常有限，例如，在表 3 中列出的设备上测试的 100-300MB&#x2F;s 用于写入操作。我们还将通过实验证明，基于交换的机制在 §6 中的设备上表现出较差的性能。</p><p>【交换带宽小，开销大】</p><h5 id="Activation-recomputation"><a href="#Activation-recomputation" class="headerlink" title="Activation recomputation"></a>Activation recomputation</h5><p>如前面提到的，前向传递期间生成的激活支配内存使用。因此，一些文献探索了在前向传递过程中丢弃中间激活，并在后向阶段需要重新计算它们。如前面提到的，前向传递期间生成的激活支配内存使用。因此，一些文献探索了在前向传递过程中丢弃中间激活，并在后向阶段需要重新计算它们。【数据库？】重新计算文献的一个关键主题是选择检查点，在此基础上提出了许多算法。</p><p>我们认为重新计算可能对设备上的学习有用，因为它不会衰减模型精度，并且不依赖于设备硬件之间的弱特征。然而，当前的算法基于一个简单的假设，即保留张量大小的总和等于总内存占用，当使用用户空间内存池时，这将不准确。据我们所知，它们都没有考虑内存池的影响。</p><p>【没有考虑内存池，时间换空间】</p><h5 id="Splitting-mini-batch-to-micro-batch"><a href="#Splitting-mini-batch-to-micro-batch" class="headerlink" title="Splitting mini-batch to micro-batch."></a>Splitting mini-batch to micro-batch.</h5><p>使用小批量 SGD 算法，权重梯度在批次中的所有样本中取平均值。因此，小批量可以进一步拆分为各种较小的批次，即微批次 [24, 55]，其梯度是所有微批次梯度的平均值。&#x3D;&#x3D;我们在图 1 中的测量表明激活内存大小与批量大小成正比&#x3D;&#x3D;，因此将小批量拆分为微批次可以显着减少所需的内存</p><p>&#x3D;&#x3D;微批次最初是为管道并行性而设计的，以实现高效的分布式机器学习&#x3D;&#x3D;。该技术很少用于云端以减少内存占用，主要是因为&#x3D;&#x3D;较小的微批大小不能充分利用云 GPU 的高并行性&#x3D;&#x3D;，如图 4 所示。小批量的时候cpu的并行性已经用满了。然而，在移动设备上，相对较小的批处理大小足以达到最大的硬件资源利用率。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221215815035.png" alt="图4:使用小批量可以充分利用移动端硬件的并行性"></p><p>此外，对于具有BatchNormalization (BN)层2的DNN模型，无法保证微批的计算正确性，这涉及到样本间的数据依赖性。尽管提出了像GhostBN[21]这样的算法来解决这个问题，但统计变化仍然是不可避免的。因此，我们将微批次视为仅用于没有 BN 层的模型的设备上内存保存技术的机会。</p><p>在每个小批结束时，累积所有M个微批的梯度，并应用于更新所有加速器的模型参数。</p><p>例如，BatchNorm在训练期间对微批使用统计信息，但累积小批统计信息用于评估</p><p>微批处理(减少激活内存)。在基于小批量的训练算法中，可以通过网络一次性发送整个小批量，然后相应地更新权重，或者通过网络依次发送小批量的更小子集(称为微批量)，积累梯度，直到整个小批量被处理完毕</p><p>这在数学上等同于在DC-Transformer等模型中的标准训练，这些模型不包含批量归一化，并且确实不会导致DC-Transformer的准确性下降。然而，微批处理改变了批归一化层的统计特性;然而，我们发现，在WideResNet上，使用小至10的微批处理进行训练不会导致准确性的任何损失</p><h5 id="Summarized-Implications"><a href="#Summarized-Implications" class="headerlink" title="Summarized Implications"></a>Summarized Implications</h5><p>通过对现有技术的先前测量，我们发现移动场景与云场景之间存在差距。一方面，在云中广泛研究的交换和压缩不能很好地适应移动设备。另一方面，微批次带来了一个新的机会，由于移动设备的硬件容量有限，其缺点得到了缓解，重新计算技术足够通用，可以支持各种硬件和模型。这些发现表明，设备上的内存优化与云有很大的不同，导致我们将Melon构建为特定于移动的框架。特别是，Melon 需要改进适当的技术（微批次和重新计算），并首次将它们整合以获得节省内存的最好处。</p><h3 id="4-THE-DESIGN"><a href="#4-THE-DESIGN" class="headerlink" title="4 THE DESIGN"></a>4 THE DESIGN</h3><p>在本节中，我们将首先概述Melon，然后详细说明其每种新技术</p><h4 id="4-1-Overview"><a href="#4-1-Overview" class="headerlink" title="4.1 Overview"></a>4.1 Overview</h4><h5 id="Design-goal"><a href="#Design-goal" class="headerlink" title="Design goal"></a>Design goal</h5><p>Melon的目标是在&#x3D;&#x3D;给定的批大小和内存预算下最大化模型的训练性能&#x3D;&#x3D;。在训练任务中，批处理大小通常由算法开发人员固定，而内存预算可以由应用程序或操作系统在运行时动态调整。</p><p>Melon改进了微批处理和重计算技术以节省内存，并与新的内存池结合以减少内存碎片。在训练没有引入交叉样本依赖的BN层的模型时，Melon采用了微批技术。Melon改进了微批处理和重计算技术以节省内存，并与新的内存池结合以减少内存碎片。在训练没有引入&#x3D;&#x3D;交叉样本依赖的BN层&#x3D;&#x3D;的模型时，Melon采用了微批技术。首先，从每个微批中&#x3D;&#x3D;聚合缓冲梯度需要时间，但与训练时间相比，开销微不足道(≤1%)。&#x3D;&#x3D;第二个开销是小批处理大小降低了内部操作执行的并行性。由于移动设备的硬件容量有限，这一开销也可以忽略不计，如§3所述。因此，我们认为Melon采用微批技术很好地解决了某些dnn的内存壁问题。</p><p>然而，BN 层成为 DNN 训练的事实标准（例如 ResNet [19] 和 Transformers [59]）。因此，Melon 更进一步，专注于支持通过重新计算包含 BN 层的通用 DNN 模型。Melonis 的关键设计，通过确定应该丢弃哪些张量或重新计算来最小化重新计算开销。然而，直接应用池和重新计算将面临一个两难境地，这两个困境都需要彼此的全局知识。为了解决这个问题，我们提出了一种新的重新计算机制，如§4.3所示</p><h5 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h5><p>如图5所示，Melon分两个阶段工作</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221224148015.png" alt="图5:Melon概览"></p><ol><li>在决策阶段，Melon生成在不同内存预算下实现最佳性能的执行计划</li><li>在执行阶段，Moon 根据计划执行 DNN 训练。</li></ol><p>这样的两阶段设计是基于DNN训练过程中规则张量访问模式的机会，已经在现有的工作[46]中采用。注意，这两个阶段都在设备上运行，&#x3D;&#x3D;决策阶段在执行阶段之前自动触发。&#x3D;&#x3D;因此，这样的设计不会为开发人员引入任何额外的编程工作(例如，在我们的实现中只有一行shell命令)。</p><ul><li><strong>Decision stage</strong></li></ul><p>在训练DNN模型之前，Melon首先运行分析迭代，通过execution Profiler获得运行时信息：被分析的信息包含了在训练过程中生成的神经网络算子和张量，包括&#x3D;&#x3D;数据流依赖关系、每个张量的大小、每个算子的计算时间、每个张量的生命周期&#x3D;&#x3D;等。&#x3D;&#x3D;然后，概要信息被提供给执行计划生成器，它会生成执行计划来详细说明内存节省的细节，例如:（1）每个张量被放在哪里（2）哪些运算符需要重新计算。&#x3D;&#x3D;此外，执行计划还包含批量拆分策略，该策略指定了&#x3D;&#x3D;没有BN层的模型的拆分批次大小。&#x3D;&#x3D;由于该技术对训练过程的统计特征没有影响，我们只需使用设备支持的最大微批处理大小，以最小化通过聚合缓冲梯度引入的额外开销。下面的小节描述了Melon如何搜索最佳执行计划。每个执行计划对应一个内存预算，因此Melon预先定义了一组内存预算，并为每个预算生成最佳的执行计划，这些计划将与用于执行阶段的模型一起存储在本地。适应一组预定义的预算，而不是任意预算，简化了Melon的内存优化设计。成本是微不足道的，因为每个执行计划在我们的实现中只需要几个 KB。</p><ul><li><strong>Execution stage</strong></li></ul><p>一旦训练任务开始，Melon 的训练引擎根据当前内存预算加载适当的执行计划，并执行计划指导的训练。&#x3D;&#x3D;当内存预算发生变化时，Melon 会检查是否需要加载新计划。如果需要，Melon 根据第 4.4 节中讨论的技术快速切换到新计划。&#x3D;&#x3D;</p><p>为了尽量减少开发人员的手动工作，Moon 的决策阶段在设备上运行以自动生成执行计划。这些计划可以存储在本地存储上，因此它们只需要生成一次，例如，当安装应用程序或从服务器获取新模型时。</p><h4 id="4-2-Lifetime-Aware-Memory-Pool"><a href="#4-2-Lifetime-Aware-Memory-Pool" class="headerlink" title="4.2 Lifetime-Aware Memory Pool"></a>4.2 Lifetime-Aware Memory Pool</h4><p>用户空间内存池[77]是训练框架[6,26,45]管理内存的常用方法。它避免了与操作系统频繁交互以分配&#x2F;释放内存块的高开销。【生活费】如今，这些框架使用的内存池按顺序为张量分配内存，并在每个分配后更新池信息。然而，这种设计忽略了 DNN 训练迭代重复的独特特征，并可能导致严重的内存碎片，例如，使用 MNN 在相同的设置中浪费高达 42% 的内存空间</p><h5 id="4-2-1-Opportunity-and-Heuristics"><a href="#4-2-1-Opportunity-and-Heuristics" class="headerlink" title="4.2.1 Opportunity and Heuristics."></a>4.2.1 Opportunity and Heuristics.</h5><p>改进内存布局的一个机会是在批处理粒度的训练中保持一致的内存操作。基于概要的内存操作信息，可以用最小的内存大小构建最佳布局。图6显示了如何通过更好的布局来节省内存的示例。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221230605606.png" alt="图6:改善内存布局"></p><p>With the on-demand strategy shown in Figure 6(a), the 𝑇2 is assigned to an address aside 𝑇1. After 𝑇1 is released, 𝑇4 cannot fit into the memory space below 𝑇2, therefore it should be located in the address above 𝑇2. Consequently, the total memory footprint is the sum of 𝑇1, 𝑇2 and 𝑇4. In the optimized allocation strategy shown in Figure 6(b), the memory footprint size can be reduced to the sum of 𝑇2 and 𝑇4.</p><p>但是，解决上述内存节省问题类似于2DSP问题[8]——一个经典的NP-Hard问题。该问题的输入由数千个张量组成，因此不可能穷尽最优解。为了获得一个接近最优的解决方案，很少的努力已经投入。&#x3D;&#x3D;这些方法通常以“大张量优先”的贪婪方式执行内存分配。&#x3D;&#x3D;相反，我们发现张量的生命期(经度)会对布局效果产生巨大影响。直观地说，一个张量在内存池中停留的时间越长，它与其他张量的“干扰”就越多，因为它将内存池分割为两个由时间戳给出的分离段。事实上，这种生命周期多样化在 DNN 训练中很普遍，可以分为两大类。</p><ol><li>&#x3D;&#x3D;激活跨越很长的生命周期，即在正向传递时产生，在反向传递时释放。与堆栈数据结构类似，它遵循“先产生后发布”(First Produce Last Release, FPLR)顺序，即越早产生激活，越晚释放激活。&#x3D;&#x3D;</li><li>其他临时张量的生命周期比激活要短得多，只跨越几个甚至一个算子。这样的观察指导我们根据每个张量的生命周期以贪婪的方式分配它们，以近似这个类2dsp问题的最优解。</li></ol><h5 id="4-2-2-Our-Approach"><a href="#4-2-2-Our-Approach" class="headerlink" title="4.2.2 Our Approach"></a>4.2.2 Our Approach</h5><p>基于前面的观察，melon采用了一种张量生命周期感知算法来优化内存布局。&#x3D;&#x3D;关键思想是将长生命期张量放在短生命期张量下面，以巩固整个内存布局。&#x3D;&#x3D;Melon迭代地将具有最长生存期的张量放置在可能的最低内存地址上。当一个张量的尾部超过当前池的大小时，内存池就会扩展。这个过程以贪婪的方式执行。利用每个张量的概要信息，Melon将内存池和张量抽象为一个2D轴和矩形，如图6所示.内存地址可以表示为相对于池底部的偏移量。在执行阶段，Melon一次请求所有的内存空间。在为每个张量分配内存时，Melon只是根据执行计划为每个张量分配池中特定的地址。</p><h4 id="4-3-Memory-Calibrated-Progressive-Recomputation"><a href="#4-3-Memory-Calibrated-Progressive-Recomputation" class="headerlink" title="4.3 Memory-Calibrated Progressive Recomputation"></a>4.3 Memory-Calibrated Progressive Recomputation</h4><h5 id="4-3-1-Problems-of-Existing-Techniques"><a href="#4-3-1-Problems-of-Existing-Techniques" class="headerlink" title="4.3.1 Problems of Existing Techniques"></a>4.3.1 Problems of Existing Techniques</h5><p>首先，先前的重新计算策略[11,46]只考虑前向传播中产生的激活。然而，我们观察到在前向和后向阶段都产生了许多碎片化和临时张量，例如图 7中的F3和B3。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221232121580.png" alt="图7:Melon的重新计算工作流程"></p><p>&#x3D;&#x3D;其次，先前的工作使重计算策略仅基于朴素峰值内存，即所有激活张量的和。&#x3D;&#x3D;事实上，在MobileNetV2与MNN的训练向前传递过程中产生的1800多个张量中，只有大约200个是需要长期使用的激活。虽然其他张量只存在很短的生命周期，但它们会占用重要的内存空间，并导致内存使用溢出。据我们所知，它们都没有考虑内存池的影响，重新计算策略会导致不准确的结果。</p><h5 id="4-3-2-Our-Approach"><a href="#4-3-2-Our-Approach" class="headerlink" title="4.3.2 Our Approach"></a>4.3.2 Our Approach</h5><p>为此，Melon引入了一种不同的重计算机制，该机制全面考虑了内存池的影响。但是，如§4.2所述，&#x3D;&#x3D;池需要所有张量的全局知识来进行分配决策，&#x3D;&#x3D;即所有张量的生命周期都可能受到重新计算的影响。只有当池的信息可访问时，即当前张量的尾部是否超过内存预算时，才能制定重计算策略。换句话说，内存池和重新计算都需要彼此的完整知识才能做出良好的决策。&#x3D;&#x3D;为了解决这个困境，我们引入了内存校准的渐进式重新计算&#x3D;&#x3D;，如算法 1 所示。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221221233043499.png" alt="image-20221221233043499"></p><p>Melon将整个算子图作为输入，并对每个张量进行平等的重新计算。</p><p>在确定要丢弃哪些张量进行重新计算时，&#x3D;&#x3D;Melon引入了度量三角形每秒(TPS) (Eq 1)来估计重新计算每个张量的好处，即大小更大、释放寿命更长&#x3D;&#x3D;、重新计算时间更短的张量具有更高的优先级，可以稍后丢弃并重新计算。释放生命期定义为丢弃和重新计算之间的生命期。更大的大小和更长的释放生命周期表明丢弃张量可以在内存池中带来更多可用空间，如图6所示</p><p>Melon的重计算机制是以递进的方式进行的。它首先通过原始的执行流(第1行)初始化内存池，然后按照原始的执行流(第12行)逐个模拟执行操作符。在模拟执行期间，每个张量都被分配了它在池中的确切位置的地址。</p><p>&#x3D;&#x3D;当一个张量的尾部超过内存预算时，&#x3D;&#x3D;重新计算机制被触发(第6-10行)。重计算机制不断丢弃TPS值最大的张量，并对内存池进行校准，直到池大小不大于预算。下一个算子的输入张量被认为没有被丢弃(第7行)。在丢弃过程中，池在当前步骤释放张量(如图6所示，删除部分矩形)。一旦一个张量被丢弃，Melon校准之后产生的所有生命周期与它有“干扰”的张量的内存地址(第8行)</p><p>当一个张量的尾部超过内存预算时，重新计算机制被触发(第6-10行)。重计算机制不断丢弃TPS值最大的张量，并对内存池进行校准，直到池大小不大于预算。下一个算子的输入张量被认为没有被丢弃(第7行)。在丢弃过程中，池在当前步骤释放张量(如图6所示，删除部分矩形)。一旦一个张量被丢弃，Melon校准之后产生的所有生命周期与它有“干扰”的张量的内存地址(第8行)。这里的干涉被定义为两个张量寿命的重叠。如图6所示，此时右侧的张量将“下沉”到较低的地址。这样的丢弃过程在内存张量上重复，直到池的大小没有超过内存预算。</p><p>当当前运算符所需要的张量在内存中没有出现时，算法分配内存并与它的源张量一起重新计算(第13-19行)。源张量被递归收集，直到输入张量出现在内存中(第14行)。通过这样的机制(第7行和第14行)，保证了操作符之间的输入依赖。重新计算张量会导致大量的时间开销，因为它会产生一些应该添加到池中的张量。因此，<strong>Melon需要扩展内存中已经存在的张量的生命周期</strong>(图6中的时间轴)。首先，池将生命周期从当前步骤延长到这些张量的生命周期长度，并且当前时间的所有“矩形”将向右移动，表明它们将在稍后生成。然后将这些张量添加到池中，池以同样的方式校准寿命与它们有干扰的张量。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222161555781.png" alt="图7:melon的工作流程"></p><p>图7演示了Melon的重新计算是如何工作的。假设拓扑顺序上的操作图为F1→F5, B5→B1 .F表示前向计算，B表示返向计算。图中的黑色箭头表示操作符图中的数据流。活化是由F1, F2和F4,F3和F5是产生临时张量的算子。假设内存预算在𝐹3之后用完，即使𝐹3的输出不是激活，具有最大TPS的𝐹2的输出也会被丢弃。在这种情况下，就地内存分配无法工作，因为应该保留F1和표F2的输出，直到它们在向后传递中没有使用。在反向传播期间，𝐵3作为中间算子来支持 𝐵2 的计算。即使在反向传递中，内存占用大小也可能超过预算，然后算法选择一个张量以与前向传递相同的方式被赶出。当张量被驱逐时，将更新每个张量的TPS。</p><h4 id="4-4-Memory-Budget-Adaptation"><a href="#4-4-Memory-Budget-Adaptation" class="headerlink" title="4.4 Memory Budget Adaptation"></a>4.4 Memory Budget Adaptation</h4><p>移动设备通常支持多应用程序执行环境，其中每个应用程序&#x2F;服务分配的硬件资源可以高度动态。这种内存适应信号可能来自操作系统或应用程序本身。为了适应新的内存预算，melon需要(i)快速响应变化，例如，在需要时释放内存，以及(ii)最小化切换执行计划的开销。</p><p>对于扩大内存预算的情况，Melon简单地采用了惰性切换策略，即等待当前批处理的训练结束，然后切换到新的执行计划。然而，在内存预算缩水的情况下，这种懒惰的策略是不可行的，因为内存需要立即释放给应用程序或操作系统。另一种直观的方法是停止-重新启动，这意味着整个内存池将被重新分配，当前批处理的所有中间结果将被丢弃。虽然它可以立即释放内存，但重新执行操作符也会导致非常高的开销。</p><p>为此，我们提出了一种动态内存调整机制，可以快速响应内存预算的变化，并根据保留的(部分)结果恢复执行。一旦有了新的预算，Melon首先缩小池大小以满足内存预算。Melon从当前内存池开始保存新内存预算的大小，并通过realloc函数转储剩余的内存预算。然后它加载新的执行计划并跳转到当前操作符的执行点。</p><p>下一个关键步骤是恢复新计划的内存布局。我们使用 A、B 和 C 分别表示旧执行计划的内存张量集、新执行计划中应该在内存中呈现的张量集和丢弃的张量集。Melon 仅在内存中的 (𝐴 −𝐶) ∩𝐵 中保留张量并转储其他张量。请注意，转储操作在物理上不需要任何内存操作，但只标记相应的内存块free。然后，Melon 将旧执行计划的剩余张量的内存地址调整为新张量。最后，Melon 根据模型的执行顺序重新计算 𝐶 − (𝐴 − 𝐵) 中的张量。通过前面的步骤，Melon可以成功地恢复内存布局，并使用新的执行计划恢复训练，而不是从头开始重新执行之前的操作符。</p><h3 id="5-IMPLEMENTATION"><a href="#5-IMPLEMENTATION" class="headerlink" title="5 IMPLEMENTATION"></a>5 IMPLEMENTATION</h3><p>我们已经在MNN (v1.1.0)[26]上完全实现了Melon的原型。据我们所知，MNN、TFLite[5]和DL4J[3]是唯一三个支持在Android设备上训练现代dnn的库。我们使用MNN是因为它在速度和内存使用方面优于其他两种，正如我们的测量(表2)和之前的工作[10]所示。注意，Melon的设计足够通用，也可以集成到其他库中。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222164639140.png" alt="表2:使用MNN更优"></p><p>我们的原型主要包括两个模块(c++中总共6.4k LoC):1)离线分析和在线内存优化执行的执行引擎;(2)执行计划生成器生成不同内存预算下的最优执行计划。请注意，它们都以自动的方式在设备上运行，不需要开发人员付出额外的努力。</p><p>虽然MNN在概念上与Android和iOS设备兼容，但我们的原型目前针对的是Android设备，因为有许多特定于操作系统的内存操作。目前原型主要支持移动CPU上的训练，因为mnn对gpu上训练相关算子的支持非常有限，即使支持的模型与CPU[10]相比性能也很差。值得一提的是，Melon的设计主要与移动GPU兼容，但需要解决一些独特的挑战，例如内存适配过程中的内存复制开销。据我们所知，MNN 是目前唯一支持移动 GPU 的设备上训练库，作为这项工作的发布。§6.7 中的评估将证明Melon 的兼容性和通用性。</p><h5 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h5><p>我们还从以往的文献中吸取教训，实施了四个基线。请注意，部分前期工作的源代码无法获取，我们尽量根据相应的论文进行复现。为了公平比较，我们在MNN上重新实现了它们。</p><ul><li>理想：我们假设设备配备了无限内存容量的理想情况，通过直接重用设备内存来实现（从而影响计算正确性）。这个baseline提供了Melon或其他基线可以达到的严格的性能上限。</li><li>vDNN[52]: 基于交换的运行时内存管理解决方案，实现dnn内存使用虚拟化。这里我们在内存和磁盘(设备上的内部存储)之间交换数据。</li><li>Sublinear: 一种分层重计算算法，当当前内存使用超过由启发式确定的阈值时，清除一个张量</li><li>Capuchin[46]：一种有效的基于张量的优化算法，结合了交换和重新计算。</li></ul><h3 id="6-EVALUATION"><a href="#6-EVALUATION" class="headerlink" title="6 EVALUATION"></a>6 EVALUATION</h3><p>在本节中，我们从各个方面评估Melon和基线，以演示Melon的效率。</p><h4 id="6-1-Experiment-Settings"><a href="#6-1-Experiment-Settings" class="headerlink" title="6.1 Experiment Settings"></a>6.1 Experiment Settings</h4><h5 id="Models-and-datasets"><a href="#Models-and-datasets" class="headerlink" title="Models and datasets"></a>Models and datasets</h5><p>我们使用表3中列出的4种典型的CNN模型对Melon进行评估，这些模型广泛应用于移动设备，包括MobileNetV1 [22]， MobileNetV2 [53]， SqueezeNet[25]和ResNet-50[19]。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222165635792.png" alt="image-20221222165635792"></p><p>对于每个模型，我们实现了两个版本:带BN层和不带BN层(在每个卷积层之后添加)。我们没有包括语言模型，因为MNN缺乏这样的支持。我们使用CIFAR-100数据集，输入大小调整为224×224×3[25,53]。</p><h5 id="Hardware-setup"><a href="#Hardware-setup" class="headerlink" title="Hardware setup"></a>Hardware setup</h5><p>我们在4个不同soc和内存容量的Android设备上进行实验(表3)。我们一直在大核上运行Melon等基线，以达到公平的比较。</p><h5 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h5><p>我们在训练期间测量内存使用、能量消耗和吞吐量。procrank 监控的内存使用。能量消耗是通过 Android 的 vFS (&#x2F;sys&#x2F;class&#x2F;power_supply) 计算的。训练吞吐量定义为每秒训练的数据样本的数量。</p><h4 id="6-2-Overall-Performance"><a href="#6-2-Overall-Performance" class="headerlink" title="6.2 Overall Performance"></a>6.2 Overall Performance</h4><p>我们首先从3个主要方面衡量Melon的整体性能，即达到相同吞吐量时支持的最大批大小，训练收敛性能，以及更大批的训练吞吐量。</p><h5 id="Maximal-batch-size-supported"><a href="#Maximal-batch-size-supported" class="headerlink" title="Maximal batch size supported"></a>Maximal batch size supported</h5><p>我们首先测量不同吞吐量所能达到的最大批大小。我们在三星Note 10上使用MobileNetV2和SqueezeNet(都带有BN层)进行实验。结果如图8所示。结果表明，Melon的内存优化在不同的吞吐量下都能很好地扩展，并且总是显著优于其他方法。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222170146596.png" alt="image-20221222170146596"></p><p>例如，当吞吐量为2.39fps时，Melon可以训练批量大小为208的MobileNetV2，而其他基线的批量大小都小于96。</p><h5 id="End-to-end-convergence-performance"><a href="#End-to-end-convergence-performance" class="headerlink" title="End-to-end convergence performance"></a>End-to-end convergence performance</h5><p>我们还评估了melon在集中式和联邦设置下端到端学习任务中的表现。我们使用的数据集是CIFAR-100。对于联邦设置，我们用10个设备初始化训练过程，所有设备上的数据分布是非iid[29]。每个设备上的数据只覆盖类的一个子集。由于实验是为了说明Melon在交易批量大小和训练速度上的有效性，因此我们在联邦学习中不考虑设备异质性[72]，只考虑三星Note10上的训练速度。对于联邦和集中式场景，其他设置都是相同的。</p><p>如图9所示，通过支持更大的批大小，Melon获得了比原始MNN更高的收敛精度，在联邦设置下，MobileNet-V2和SqueezeNet分别为3.94%和3.20%。在集中设置下，Melon的收敛精度分别提高了1.98%和2.04%。另一方面，Melon显著减少了训练时间，达到相同的精度。例如，与原始MNN相比，MobileNetV2和Squeeze-Net的收敛精度分别减少2.80×和3.48×的时间(58.22%和59.18%)。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222170958494.png" alt="图9:melon支持更大批量训练"></p><h5 id="Throughput-with-the-same-batch-size"><a href="#Throughput-with-the-same-batch-size" class="headerlink" title="Throughput with the same batch size"></a>Throughput with the same batch size</h5><p>然后，我们通过改变不同的(放大的)批大小来全面研究Melon的训练性能，这些批大小在不使用内存节省技术的情况下无法训练。</p><p>实验在4个设备上进行，2个是有BN层的模型，2个是没有BN层的模型。对于每个组合，我们选择2-3个批大小，例如，如果原始最大批大小是32，我们使用64、96和128作为测试批大小。结果分别显示在图11和图12中</p><p>我们的主要观察结果是，Melon的性能始终显著优于其他备选优化基线，与Ideal基线相比，它的性能通常与Ideal基线相似。例如，在BN层模型上(图11)，Melon的吞吐量比vDNN高1.51× - 3.49×higher，比sublinear高1.13× - 3.86，比Capuchin高1.01× - 4.01。Melon实验表明，其优势在较大的batch size上更加明显，例如在64和128 batch size的红米Note9 Pro上训练MobileNetV2时，分别比Capuchin提高了3.25×和3.34×。然而，Melon和Ideal基线之间的性能差距总是随着更大的批处理规模而增加(例如，在红米Note9 Pro上训练MobileNetV2时，从10.67%增加到21.21%)，因为Melon需要更积极地丢弃和重新计算引起计算开销的张量。在基线中，vDNN在大多数情况下表现最差，因为在§3中提到的移动设备上的数据交换速度有限。注意Capuchin的改进几乎得益于重新计算，因为交换引入了严重的同步开销。它还忽略了内存池的影响，这意味着它将浪费更多的空间，重新计算更多的张量来支持更大的批处理大小，导致吞吐量损失。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222171615052.png" alt="image-20221222171615052"></p><p>对于没有BN层的模型(图12)，Melon在任意批量大小下几乎可以赶上Ideal基线的性能(损失仅小于1%)。与其他优化基准相比，性能提升也非常显著，魅族16t平均提升1.77×(最高2.66×)，红米Note8平均提升1.57×(最高2.15×)。这是因为，对于没有BN层的模型，Melon利用了微批处理技术，如§3所述，性能下降很小。注意，当批大小相对较小时，其他基线也可以实现相对较高的性能。这是因为去掉了所有的BN层，BN层的数量接近卷积层。将有更少的激活和更少的计算，导致高性能的基线。然而，与Melon不同的是，这些基线的性能随着大批处理而衰减。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222172934586.png" alt="image-20221222172934586"></p><h4 id="6-3-Memory-Budget-Adaptation"><a href="#6-3-Memory-Budget-Adaptation" class="headerlink" title="6.3 Memory Budget Adaptation"></a>6.3 Memory Budget Adaptation</h4><p>然后，我们评估了§4.4中所介绍的melon的内存预算适应设计。我们关注内存预算减少的情况，因为它在实践中更具挑战性。实验使用三星Note 10上的2个型号(MobileNetV2和SqueezeNet)。我们选择了2个不同的适应场景:批大小为128时从6GB切换到5GB，批大小为64时从4GB切换到3GB。注意，在每种情况下，如果不进行内存优化，内存预算都不足以训练批处理大小。我们还选择了3个自适应点，即当执行进度达到25%，50% 和 75%。本实验比较的基线是停止重启，如第 4.4 节所述。</p><p>结果如图 10 所示。适应开销是新计划在适应发生时达到与旧计划相同的运算符的时间成本，归一化为在适应时简单地丢弃所有张量的停止重启方法。相比之下，Moon 产生的适应开销要少得多，即 4.27%-54.50%。Meon 的开销在后验执行点增加，主要是因为要重新计算的张量数以恢复新执行计划的内存布局会增加。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222173253220.png" alt="image-20221222173253220"></p><p>为了进一步了解自适应性能，我们还将开销分解为两大类：内存中的张量重新排列和根据新的执行计划重新计算丢失的张量。图10显示，在大多数情况下，重新计算开销占总调整开销的主导地位，尤其是在后执行点。这是因为在移动设备上，内存移动速度比计算速度快得多。</p><h4 id="6-4-Energy-Consumption"><a href="#6-4-Energy-Consumption" class="headerlink" title="6.4 Energy Consumption"></a>6.4 Energy Consumption</h4><p>由于移动设备的电池容量有限，能耗是另一个需要优化的关键指标。尽管Melon主要针对高训练吞吐量而不是降低能耗进行了优化，但我们仍然在这方面与其他基线一起对其进行了评估。在这里，我们在魅族16t设备上测试了两种型号（MobileNetV2和带有BN层的SqueezeNet）。结果如图13所示，数字标准化为Idealbaseline。</p><p>这表明 Mlon 显着降低了与基线相比的能量消耗，即 22.00%-49.43%。与交易基线相比，Moon 的能量消耗平均仅为 11.4%，而最佳情况下仅低 2.1%。Moon 的改进主要来自训练时间的减少。与训练吞吐量相比，vDNN 的性能得到了显着提高，因为读取&#x2F;写入操作的能量比计算少（约 2.5 倍的差距）。然而，由于训练时间变长，它仍然消耗比 Melon 更多的能量。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222173543993.png" alt="image-20221222173543993"></p><h4 id="6-5-Ablation-Study"><a href="#6-5-Ablation-Study" class="headerlink" title="6.5 Ablation Study"></a>6.5 Ablation Study</h4><p>我们进一步对每种技术带来的好处进行了细分分析，即分别具有生命周期感知内存池或内存校准的渐进式重新计算。我们评估了每种方法可以通过不同吞吐量实现的最大批量大小。我们在三星 Note10 上使用 Copy2 和 SqueezeNet 进行实验。结果如图 14 所示。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222173619623.png" alt="image-20221222173619623"></p><p>我们观察到这两种技术对改进都有不小的贡献。例如，当MobileNetV2的吞吐量为3.07fps时，我们的生命周期感知内存池和重新计算技术可以达到的最大批处理大小分别为40和80。结合它们，批大小可以增加到112，这几乎是线性成比例的。由于内存访问模式对于一个模型和一个批处理大小保持相同，因此池带来的改进在不同的吞吐量上保持相同。我们还发现，对于吞吐量较低的两个模型，Melon带来的改进大于pool和recomputation带来的改进之和。原因是随着批大小的增加，生命周期长的张量越来越少，这可以引入更多的机会来执行生命周期感知分配，如图6所示。</p><h4 id="6-6-Complexity-Analysis"><a href="#6-6-Complexity-Analysis" class="headerlink" title="6.6 Complexity Analysis"></a>6.6 Complexity Analysis</h4><p>我们衡量算法的成本，即生成执行计划的时间。首先，分析的时间等于训练一批的时间，与图9所示的整个训练过程相比，这几乎可以忽略不计。注意，在这个过程中我们重叠了所有张量，即所有张量共享同一块内存，因为统计值对分析没有影响。例如，使用三星Note10对批大小为32的MobileNetV2进行分析训练，耗时约10.3s，耗时约147MB。记录每个操作员延迟的额外时间也可以忽略不计。</p><p>Melon线下时间的主要来源是执行计划的生成。我们以在三星Note10上训练SqueezeNet为例，测量了这个开销来分析算法的复杂性。我们使用的批大小从64到172，步骤为16。实验结果表明，生成一个计划平均需要10.9s。由于生成的计划可以永久存储，所以这种延迟只会引起一次射击，因此在实践中，我们的算法的成本也是可以接受的</p><h4 id="6-7-GPU-support"><a href="#6-7-GPU-support" class="headerlink" title="6.7 GPU support"></a>6.7 GPU support</h4><p>我们进行了一个实验来探索Melon在移动GPU上的性能。我们测量支持的最大批大小。设置与§6.2相同。结果如图15所示。这表明Melon在不同的吞吐量下也可以达到最大的批量大小。但是，结果不如在CPU上那么令人印象深刻，因为Melon主要针对CPU进行了优化。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221222174919246.png" alt="image-20221222174919246"></p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MobiSys22</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>picgo 图床搭建</title>
    <link href="/2022/12/20/picgo-%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/"/>
    <url>/2022/12/20/picgo-%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="typora-picgo配置-阿里云-OSS"><a href="#typora-picgo配置-阿里云-OSS" class="headerlink" title="typora picgo配置(阿里云 OSS)"></a>typora picgo配置(阿里云 OSS)</h2><p>[toc]</p><h4 id="1-typora-配置"><a href="#1-typora-配置" class="headerlink" title="1. typora 配置"></a>1. typora 配置</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/8b1ad795b6b116b1857b66a567f64918.png" alt="image-20221220154039516"></p><h4 id="2-picgo-配置"><a href="#2-picgo-配置" class="headerlink" title="2. picgo 配置"></a>2. picgo 配置</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/c7561d3e3e2fd571d5233fc9b2a4b350.png" alt="image-20221220154130710"></p><p>KeyID 和 KeySecret点击头像处的AccessKey管理获取</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/1f601a1d16044099f0563199717293a9.png" alt="image-20221220154222795"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/fc48b3425cc7707894c8762cefa2b3df.png" alt="image-20221220154629831"></p><p>进入你的bucket，点击概览</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/f62383f1c0f05dde8b9ed204a45b4e60.png" alt="image-20221220154749368"></p><p>设置完成后点击确认。</p><h4 id="3-验证"><a href="#3-验证" class="headerlink" title="3. 验证"></a>3. 验证</h4><p>重启typora，配置自动上传，点击 验证图片上传选项</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/0ae026b137da7e4a2106d76a09e0f853.png" alt="image-20221220155001090"></p><p>结果：上传成功。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/e0e3c3aed2a0ab2e83577b174924809e.png" alt="image-20221220155120565"></p>]]></content>
    
    
    <categories>
      
      <category>技术博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>picgo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vsomeip 快速入门</title>
    <link href="/2022/12/20/vsomeip-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <url>/2022/12/20/vsomeip-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="vsomeip-快速入门"><a href="#vsomeip-快速入门" class="headerlink" title="vsomeip 快速入门"></a>vsomeip 快速入门</h2><h4 id="1-下载仓库"><a href="#1-下载仓库" class="headerlink" title="1. 下载仓库"></a>1. 下载仓库</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/COVESA/</span>vsomeip.git<br></code></pre></td></tr></table></figure><h4 id="2-编译"><a href="#2-编译" class="headerlink" title="2. 编译"></a>2. 编译</h4><h5 id="2-1-安装相关依赖"><a href="#2-1-安装相关依赖" class="headerlink" title="2.1 安装相关依赖"></a>2.1 安装相关依赖</h5><p>我的ubuntu 版本是20.04，所以以ubuntu 20.04为例。</p><p>vsomeip依赖 Boost，所以我们要先安装 Boost(版本在1.55-1.74之间)，官方文档上对应的boost包版本过低。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vim">sudo apt-<span class="hljs-built_in">get</span> install gcc g++ <span class="hljs-keyword">make</span><br>sudo apt install cmake<br>sudo apt-<span class="hljs-built_in">get</span> install libboost-<span class="hljs-built_in">system</span>-dev libboost-thread-dev libboost-<span class="hljs-built_in">log</span>-dev<br>sudo apt-<span class="hljs-built_in">get</span> install asciidoc <span class="hljs-keyword">source</span>-<span class="hljs-keyword">highlight</span> doxygen graphviz<br></code></pre></td></tr></table></figure><h5 id="2-2-编译vsomeip"><a href="#2-2-编译vsomeip" class="headerlink" title="2.2 编译vsomeip"></a>2.2 编译vsomeip</h5><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">cd</span> vsomeip<br><span class="hljs-built_in">mkdir</span> build<br><span class="hljs-keyword">cd</span> build<br>cmake ..<br><span class="hljs-keyword">make</span><br>sudo <span class="hljs-keyword">make</span> install<br></code></pre></td></tr></table></figure><p>运行上述命令进行编译vsomeip库，其中运行make之后的编译很慢，大约需要四五分钟，耐心等待就好。</p><h5 id="2-3-编译hello-world-example"><a href="#2-3-编译hello-world-example" class="headerlink" title="2.3 编译hello_world example"></a>2.3 编译hello_world example</h5><p>clone 下载的vsomeip中自带一个demo hello_world，我们先编译对应的helloworld程序</p><p>Helloworld程序的编译方法也可以查看自带的readme vsomeip&#x2F;examples&#x2F;hello_world&#x2F;readme</p><p>回到build目录下，执行下列命令：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">cmake <span class="hljs-params">--build</span> . <span class="hljs-params">--target</span> hello_world<br><span class="hljs-keyword">cd</span> <span class="hljs-string">./examples/hello_world/</span><br>make<br>sudo make install <br>sudo ldconfig<br></code></pre></td></tr></table></figure><p>运行后编译就完成。</p><h4 id="3-运行"><a href="#3-运行" class="headerlink" title="3. 运行"></a>3. 运行</h4><p>编译完成之后，会在对应的编译目录下生成对应helloworld的二进制程序：hello_world_client和hello_world_service</p><p>此时不能安装readme里面写的执行</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs routeros">Running Hello World Example<br>---------------------------<br><br>The Hello World Example should be <span class="hljs-built_in">run</span> on the same host.<br>The<span class="hljs-built_in"> network </span>addresses within the configuration files need <span class="hljs-keyword">to</span> be adapted <span class="hljs-keyword">to</span> match<br>the devices addresses.<br><br><span class="hljs-keyword">To</span> start the hello world<span class="hljs-built_in"> client </span><span class="hljs-keyword">and</span><span class="hljs-built_in"> service </span><span class="hljs-keyword">from</span> their build-directory <span class="hljs-keyword">do</span>:<br><br>HOST1:<br><span class="hljs-attribute">VSOMEIP_CONFIGURATION</span>=../helloworld-local.json \<br><span class="hljs-attribute">VSOMEIP_APPLICATION_NAME</span>=hello_world_service \<br>./hello_world_service<br><br>HOST1:<br><span class="hljs-attribute">VSOMEIP_CONFIGURATION</span>=../helloworld-local.json \<br><span class="hljs-attribute">VSOMEIP_APPLICATION_NAME</span>=hello_world_client \<br>./hello_world_client<br></code></pre></td></tr></table></figure><p>我们在 …&#x2F; 目录下并不能找到 helloworld-local.json这个文件。</p><p>所以我们需要将 vsomeip&#x2F;examples&#x2F;hello_world&#x2F;helloworld-local.json 文件复制到二进制文件生成的目录下才能执行。</p><p>复制后，vsomeip&#x2F;buuld&#x2F;examples&#x2F;hello_world的目录结构为</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/09af136ba396ba4f6a66d9df4eac231a.png" alt="hello_world目录结构图"></p><p>下面运行</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros">HOST1运行service:<br>env <span class="hljs-attribute">VSOMEIP_CONFIGURATION</span>=./helloworld-local.json \<br><span class="hljs-attribute">VSOMEIP_APPLICATION_NAME</span>=hello_world_service \<br>./hello_world_service<br><br>HOST1运行client：<br>env <span class="hljs-attribute">VSOMEIP_CONFIGURATION</span>=./helloworld-local.json \<br><span class="hljs-attribute">VSOMEIP_APPLICATION_NAME</span>=hello_world_client \<br>./hello_world_client<br></code></pre></td></tr></table></figure><p>运行结果如下：</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/ca74a1ab17f48773acf382349fec05bf.png" alt="service端运行结果"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/e05dcd7914bd016575fbdbf09053f1b9.png" alt="cilent端运行结果"></p><p>此时，一个简单的vsomeip cilent端和service端的通信就搭建完成了。</p>]]></content>
    
    
    <categories>
      
      <category>技术博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蔚来实习</tag>
      
      <tag>vsomeip</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo 博客新建文章</title>
    <link href="/2022/12/20/hexo-%E5%8D%9A%E5%AE%A2%E6%96%B0%E5%BB%BA%E6%96%87%E7%AB%A0/"/>
    <url>/2022/12/20/hexo-%E5%8D%9A%E5%AE%A2%E6%96%B0%E5%BB%BA%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="hexo-博客新建文章"><a href="#hexo-博客新建文章" class="headerlink" title="hexo 博客新建文章"></a>hexo 博客新建文章</h2><h4 id="创建文章"><a href="#创建文章" class="headerlink" title="创建文章"></a>创建文章</h4><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gauss">hexo <span class="hljs-keyword">new</span> [layout] &lt;<span class="hljs-built_in">title</span>&gt;<br><span class="hljs-meta"># layout 默认为post</span><br></code></pre></td></tr></table></figure><h4 id="Front-matter-设置"><a href="#Front-matter-设置" class="headerlink" title="Front-matter 设置"></a>Front-matter 设置</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/20200916181236318.png" alt="在这里插入图片描述"></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">title:</span> <span class="hljs-string">如何在hexo上创建一篇文章</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2020-09-16 19:33:46</span><br><span class="hljs-attr">categories:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">博客</span><br><span class="hljs-attr">tags:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">创建文章</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><h4 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h4><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">hexo g</span><br><span class="hljs-attribute">hexo d</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mobisys22 CoDL 笔记</title>
    <link href="/2022/11/27/Mobisys22-CoDL-%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/11/27/Mobisys22-CoDL-%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="Mobisys22-CoDL-笔记"><a href="#Mobisys22-CoDL-笔记" class="headerlink" title="Mobisys22-CoDL 笔记"></a>Mobisys22-CoDL 笔记</h2><p>论文标题：“CoDL: Efficient CPU-GPU Co-execution for Deep Learning Inference on Mobile Devices”</p><p>主讲人：Peter Wan 万 晔</p><p>主讲时间：2022-11-22 19：00</p><p>PPT地址：<a href="https://liumengyang.xyz/ReadingGroup/slides/CoDL.pdf">https://liumengyang.xyz/ReadingGroup/slides/CoDL.pdf</a></p><h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>​异构处理器上的并发推理执行对于提高日益繁重的深度学习 (DL) 模型的性能至关重要。但是目前的推理框架只能一次使用一个处理器。这主要是因为有两大挑战。</p><ol><li>需要减小数据开销</li><li>需要在处理器之间很好地划分每一个算子</li></ol><p>​本文提出了CoDL，一种用于移动设备上CPU与GPU并发的深度学习推理框架。它可以充分利用异构处理器对模型的每个算子进行加速。它集成了两种新技术</p><ol><li><em>hybrid-type-friendly data sharing</em>：允许每个处理器使用其有效的数据类型进行推理。为了减小开销，我们还提出了（hybrid-dimension partitioning）混合维度分区和（operator chain）算子链方法。</li><li><em>non-linearity- and concurrency-aware latency prediction</em>：通过为不同的处理器构建一个非常轻量而且准确的延迟预测器来指导合适的算子分区。</li></ol><p>​在不同的深度学习模型上对CoDL进行评估，最终获得4.93$\times$的速度提高，和62.3%的性能节约。</p><h3 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1 INTRODUCTION"></a>1 INTRODUCTION</h3><p>背景：深度学习 (DL) 现在是各种移动应用程序的支柱。由于在隐私保护、互联网弹性和低云操作开销方面的优势，与云端（on-cloud）推理相比，设备推理(on-device)正在获得动力。然而，目前的设备端推理只能对一些简单模型实现可接受的响应能力，而对于其他模型则不行。例如，用于对象检测的 YOLO 需要超过 200 毫秒才能在主要的移动处理器（即移动 CPU 或 GPU）上运行。为了提高响应能力，一个自然的想法是在移动设备上同时利用异构处理器是否会有效。</p><p>​手机SOC的特定设计提供了这种可能，原因有两个</p><ol><li>相当的CPU与GPU性能。与PC端相差几个数量级不同，移动端的CPU与GPU在深度学习推理方面具有相似的性能，因此它们可以并排使用。</li><li>统一的内存。不同于服务器机器通常有单独的CPU和GPU内存，移动CPU和GPU使用统一的内存。它可以避免不同内存之间的数据复制。</li></ol><p>​但是，目前的推理框架只能用一次使用一个处理器，并且存在并发执行的两大挑战</p><ol><li><p><em>how to reduce data sharing overhead</em>：如何减少数据共享开销。尽管使用统一内存，但仍然需要相当大的开销来确保共享数据的一致性。例如，要在 CPU 和 GPU 上同时运行模型的算子，最后一个算子的输出需要在两个处理器之间共享。</p><p>如果不同的处理器使用不同的数据类型，这会导致处理器同步、数据映射以及潜在的数据转换。如果没有适当的策略，数据共享开销很容易超过并发带来的收益。</p></li><li><p><em>how to fairly partition each operator of a model between processors</em>：如何在处理器之间公平划分模型的每个算子。不同分区candidates的online measurements是不可行的。</p><p>需要一个轻量级和准确的延迟预测器，更重要的是，需要了解引入并发后带来的所有可能开销。</p></li></ol><p>​现在的研究工作还不能很好地解决上述挑战。μlayer和OPTIC可以让CPU和GPU在移动设备上并行使用。但是，对于挑战1，它们使用了相同的数据类型（即buffer type）来简化数据共享。这种设计是的CPU+GPU的协同执行甚至比GPU单独执行更慢，因为GPU使用了低效的数据类型。对于挑战2，为了进行算子分区，它们通过对计算量（FLOPs）进行线性回归来对算子的时延进行建模。尽管这个模型是轻量级的，但预测精度很差（&lt;10%）。原因是基于 FLOPs 的预测器无法捕获真实的延迟行为。还有一些延迟预测器，它们使用复杂的黑盒机器学习模型来捕获延迟行为并实现较高的准确度。然而，这些模型的运行开销很大。例如，nn-Meter对于一个卷积算子的模型大小超过800MB，太庞大而无法在移动设备上运行以进行实时预测。此外，这些预测器都没有考虑与并发相关的开销。</p><p>​为了解决这两种挑战，本文提出了CoDL。CoDL的设计源于两个关键发现。</p><ol><li>不同的处理器偏好不同的数据类型以获得最佳性能。例如，我们观察到对于卷积而言，与缓冲区类型（buffer type）相比，在 Adreno GPU 上使用图像类型（image type）可以实现 3.5 倍的加速。所以需要对每个处理器使用高效类型进行协同执行。</li><li>为了使延迟预测器既准确又轻量级，必须将平台特征（platform features）整合到模型中，而不是纯粹的黑盒学习。</li></ol><p>​基于这两个关键发现，CoDL提出了两种技术。</p><ol><li><p><em>Hybrid-type-friendly data sharing</em>：它允许异构处理器使用不同的数据类型进行推理。然后，为了减少数据共享开销，我们提出了混合维度分区（hybrid-dimension partitioning）和算子链（operator chain）方法。</p><p>混合维度分区可以为每个算子shape选择最佳的分区维度，以实现数据共享开销和处理器利用率之间的权衡。</p><p>算子链确保链上的算子只需要本地数据来执行，而不是来自其他处理器的共享数据，以避免数据共享开销。</p></li><li><p>*Non-linearity-and concurrency-aware latency prediction.*：CoDL可以通过构建轻量级但准确的延迟预测器来公平并online地划分算子。我们的见解是，其他学习延迟预测器的高复杂性是捕获由不同算法和执行块（different algorithms and execution blocks）引起的非线性延迟响应。因此，我们公式化来计算每个算法块以提取非线性。只有线性部分被一个极轻量的模型学习。此外，我们的预测器是第一个考虑所有与并发相关的开销的人。</p></li></ol><p>​对于给定的模型，可以根据预测器得出每个算子的最佳数据分区和共享计划（the best data partitioning and sharing plan）。 CoDL 然后协调处理器来执行计划。我们基于最先进的 (SOTA) 移动推理框架 MACE实现CoDL。在包括 Snapdragon 855、865 和 888 以及 Kirin 990 在内的商用现货 (COTS) 移动设备上的实验表明，与 SOTA 协同执行系统相比，CoDL 可以实现平均 3.43 倍的加速和 62.3% 的节能。通过考虑非线性特征，我们的预测器在预测 CPU 和 GPU 上算子的运行时延迟方面分别达到了 86.21% 和 82.69% 的准确率，并且推理开销低（每个算子 &lt; 1 ms）。此外，使用一次性收集的数据样本（运行时间小于 1.5 小时的 6000 个样本），预测器可以以设备上的方式进行训练（be trained in an on-device manner），延迟范围为 1 到 2 秒。</p><p>​主要的贡献如下：</p><ol><li>深入分析CPU+GPU并发执行的性能瓶颈</li><li>提出在 CPU 和 GPU 之间进行混合类型友好的数据共享，利用混合维度分区和算子链来减少共享开销</li><li>提出极轻量但准确的非线性和并发感知延迟预测</li><li>实施端到端 CoDL 框架并证明其性能优于最先进的解决方案</li></ol><h3 id="2-MOTIVATION-AND-ANALYSIS"><a href="#2-MOTIVATION-AND-ANALYSIS" class="headerlink" title="2 MOTIVATION AND ANALYSIS"></a>2 MOTIVATION AND ANALYSIS</h3><p>​在设计CoDL之前，我们首先通过分析SOTA（SOTA model)：state-of-the-art model，并不是特指某个具体的模型，而是指在该项研究任务中，目前最好&#x2F;最先进的模型。SOTA result：state-of-the-art result，指的是在该项研究任务中，目前最好的模型的结果&#x2F;性能&#x2F;表现。）推理系统来探索协同执行的性能瓶颈。</p><p>​我们按照μplayer（最佳协同处理模型）与MACE（最佳单处理器执行系统），分别进行了测试。在骁龙855平台上，CPU与GPU协同运算的μLayer要比但单CPU或GPU的MACE执行地慢。深入分析系统，当前并行系统的性能问题在于：</p><ol><li>不同的处理器使用了统一的数据类型</li><li>忽视了数据共享的开销</li><li>工作负载划分不合理</li></ol><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116210803204.png" alt="image-20221116210803204"></p><p>​统一的数据类型对于异构处理器协同执行来说效率不高。为了简化数据共享，当前的协同执行系统为不同的处理器使用通用数据类型。例如，buffer type被CPU和GPU都支持，因此可以被μLayer调用。缓冲区类型将数据组织成连续的和指针可访问的块。但是，我们发现图像类型（image type）在 Adreno GPU 上比缓冲区更有效。图像类型将数据组织成多维块以方便渲染,它利用 GPU 上的快速 L1 Cache 缓存来加速数据访问</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116210915345.png" alt="image-20221116210915345"></p><p>​图说明了使用图像和缓冲区类型进行具有不同输入形状的 3×3 卷积的性能差异。</p><p>​因此，要充分利用每个异构处理器，就应该使用相应的高效数据类型</p><p>​并行的数据共享开销不可忽略，尤其是对小算子而言。协同计算带来了数据共享开销，以确保数据的一致性。当前的协同系统忽视了这种开销。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116211339790.png" alt="image-20221116211339790"></p><p>​上图展示了算子在CPU和GPU协同执行过程中的延迟组件。假设算子输入由 GPU 上的最后一个算子生成，现在在 CPU 和 GPU 之间共享以共同执行。在算子的计算开销之外，额外的开销来自于：</p><ol><li>数据转换：如果使用了不同的数据类型</li><li>数据映射，将输入映射到CPU地址空间</li><li>同步，通知其他处理器完成映射（预同步）获计算（后同步）</li><li>数据取消映射，取消映射CPU地址空间的输出</li></ol><p>​这些开销都是不可忽略的。特别是对于小型算子，它很容易成为主要开销并抵消 CPU-GPU 协同执行带来的增益。图 4 演示了一个例子</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116212011290.png" alt="image-20221116212011290"></p><p>​尽管协同执行将执行延迟从 1126μs 减少到 599μs，数据共享开销贡献了 1074μs，导致 1.5 倍的减速。</p><p>​因此，协同执行系统应该以减少开销为目标，只有当收益超过开销时才并发执行运算符。</p><p>​用于协同执行的平衡工作负载分区需要轻量级且准确的延迟预测器。当前的协同执行系统通常使用轻量级模型的预测延迟来指导处理器之间的工作负载分配。例如，μlayer使用基于 FLOPs 的线性模型来预测延迟。轻量级延迟模型适用于在线预测。然而，它太不准确了（&lt;10%）。由于工作负载不平衡，不准确的延迟预测反过来会导致推理性能不佳。上图中，鉴于最佳分区率为 90%，基于 FLOPs 的预测器通过在 GPU 上分配 60% 的运算符导致 4 倍的减速。</p><p>​预测不准确的原因是延迟与FLOPs不是简单的线性关系，而是受算法实现、数据块大小等平台特性（platform features）影响很大。如图 6 所示，随着 GPU 和 CPU 的 FLOPs 增加，延迟显示出非线性响应</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116212820722.png" alt="image-20221116212820722"></p><p>​还有一些工作只在准确预测延迟，如nn-meter，它使用黑盒机器学习方法来学习基于多个算子超参数的延迟响应。然而，由于缺乏对底层平台特征的了解，黑盒方法以模型尺寸大为代价获得了令人满意的精度（例如，超过 800 MB 用于 nn-Meter 的卷积）和不可行的执行时间（例如，nn-Meter 在 PC 上超过 80 毫秒）。部署在移动设备上是不切实际的。因此，协同执行系统需要一个可以结合平台特性的延迟预测器，从而既轻便又准确。</p><h3 id="3-CODL-OVERVIEW"><a href="#3-CODL-OVERVIEW" class="headerlink" title="3 CODL OVERVIEW"></a>3 CODL OVERVIEW</h3><p>​为了在异构处理器上实现协同执行的最佳性能，我们提出了三个设计原则</p><ol><li>充分利用每个处理器的计算能力</li><li>最小化由数据共享引起的额外开销，即数据转换、映射和同步</li><li>最佳分区和平衡异构处理器之间的工作负载。</li></ol><p>​在这些原则的指导下，我们设计了 CoDL。它分两个阶段运行，即离线阶段和在线阶段，如图 7 所示。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116213426444.png" alt="image-20221116213426444"></p><p>​在离线阶段，CoDL 设计了一个轻量级但有效的延迟预测器来指导在线阶段的算子划分。预测器可以做到轻量和有效，原因在于：</p><ol><li>它考虑了所有数据共享开销，包括数据转换、映射和同步</li><li>它解析地制定了由平台特性引起的非线性延迟响应，并且只需要通过极轻量级的线性回归模型为每个实现的内核学习基本执行单元的延迟</li></ol><p>在线阶段由两个模块组成，the operator partitioner and the operator co-executor.。operator partitioner 的作用是为输入的 DL 模型制定最优的 operator 分区方案。基于latency predictor，它采用两种技术，即混合维度分区和运算符链，来完成这个功能。分区器首先通过混合维度分区技术为每个算子找到最佳分区维度（高度或输出通道）和比率（例如，0.1、0.2，…）作为base plan。根据base plan规划，通过算子链技术寻找算子上链，链上算子无需共享数据。来自分区器的最终分区计划是找到一组链的集合，每个都有链接的算子和链上的一些设置，即partitioning ratio and dimension。通过该计划，预先为 GPU 和 CPU 安排了模型权重，以避免每次推理调用的重新转换。</p><p>​operator co-executor根据分区计划协调operators的同步执行，针对不同的处理器使用其友好的数据类型。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116214804551.png" alt="image-20221116214804551"></p><p>​如图 8 所示，在链的开头，CoDL 首先在 CPU 和 GPU 之间共享数据。假设 GPU 友好类型为默认数据类型，CoDL 将分区输入特征图从 GPU 友好类型（例如，Adreno GPU 上的图像类型）转换为 CPU 友好类型。然后，CPU 和 GPU 同时执行一条链中的所有算子。在一条链的末端，GPU 将 CPU 上生成的数据转换回 GPU 友好类型，并与 GPU 输出结合在一起作为下一条链的输入。</p><h3 id="4-HYBRID-TYPE-FRIENDLY-DATA-SHARING"><a href="#4-HYBRID-TYPE-FRIENDLY-DATA-SHARING" class="headerlink" title="4 HYBRID-TYPE FRIENDLY DATA SHARING"></a>4 HYBRID-TYPE FRIENDLY DATA SHARING</h3><p>​CoDL 支持为每个处理器使用高效的数据类型，但是这也进一步增加的数据开销。本节介绍CoDL的两种数据共享优化技术，即混合维度划分和算子链。它们通过实现数据共享和计算开销之间的权衡来加速算子的共同执行</p><h4 id="4-1-Hybrid-dimension-partitioning"><a href="#4-1-Hybrid-dimension-partitioning" class="headerlink" title="4.1 Hybrid-dimension partitioning"></a>4.1 Hybrid-dimension partitioning</h4><ul><li><strong>Performance impact analysis</strong></li></ul><p>为了进行协同运算可以沿不同维度划分算子的张量，包括OC,H,W。同的维度导致不同的性能影响。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116215951730.png" alt="image-20221116215951730"></p><p>​首先，分区维度影响数据共享开销。确保处理器之间共享数据的一致性需要相当大的开销。因此，减少共享数据量很重要。模型权重在推理过程中是一致的。它们可以预先分配在每个处理器上，不需要动态共享。但是，每个算子的输入特征图需要动态共享，因为它是由最后一个算子在推理过程中生成的。</p><p>​因此，考虑到数据共享开销，在维度H上进行分区比在维度OC上进行分区更可取。对于OC分区，整个输入特征图在 CPU 和 GPU 之间共享。相比之下，只有部分特征图（以及用于过滤处理的填充数据）被共享用于H分区。</p><p>​其次，分区维度影响处理器利用率。尽管在H上进行分区具有较少的数据共享开销，但我们发现它并不总是意味着较少的运行时间。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116220640456.png" alt="image-20221116220640456"></p><p>​原因在于，与OC相比，H分区可能会降低处理器利用率，这具体取决于运算符形状</p><p>​为了利用处理器的内核间和内核内并行性，需要将算子的张量分成块并调度到不同的内核上运行。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116220930984.png" alt="image-20221116220930984"></p><p>​一个名为工作组（work group）的块被安排在 GPU 核心上运行。为了有效地利用内核中的许多 ALU，称为 warp 的基本执行单元同时为多个线程（例如 64 或 128）执行相同的指令。因此，工作组应该提供足够的线程来填充 warp。或者会有空闲的 ALU。</p><p>​<strong>H分区速度慢的原因</strong>：OC上的维度很小（为了避免许多过滤器对缓存造成的压力，当H和W比较小的时候（13 × 13），就没有足够的线程来填充warp），导致GPU利用率和性能降低</p><p>​第三，分区维度影响数据访问开销。为了更快的数据访问，分区维度应该与张量布局一致，并确保共享数据连续存储在内存中。按H分区是连续的，按W分区是不连续的。</p><ul><li><strong>Determining the partitioning dimension.</strong></li></ul><p>​应根据每个算子shape对数据共享开销和处理器利用率的影响来确定分区维度。因此，我们提出了 CoDL 的混合维度划分。它将影响因素整合到延迟预测器中。CoDL快速评估不同的分区计划，为每个算子找到最佳的分区维度和比率。选择最小的延迟最为最后的分区维度。</p><h4 id="4-2-Operator-chain"><a href="#4-2-Operator-chain" class="headerlink" title="4.2 Operator chain"></a>4.2 Operator chain</h4><p>​我们提出了运算符链技术来减少需要共享数据的运算符数量，而不是在每个运算符之后共享数据。数据只需要在链的开始和结束时共享，链中的其他算子使用本地生成的数据，但不使用来自其他处理器的数据。</p><ul><li><strong>Performance impact analysis</strong></li></ul><p>挑战：如何快速决定在 DL 模型中链接哪些算子。不正确的链接运算符会对性能产生负面影响。</p><p>首先，一个链的分区比例对于它的每个算子的性能来说可能并不理想。该比率是链中所有算子的折衷。其次，链越长，填充越多，因此有更多的额外计算。卷积需要在特征图的边界上填充以进行过滤处理。padding的公式如下</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116222215715.png" alt="image-20221116222215715"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116222251134.png" alt="image-20221116222251134"></p><p>​要在链中再添加一个算子，填充将沿着链传播到第一个算子。这给每个算子增加了越来越多的冗余计算。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221119163805604.png" alt="image-20221119163805604"></p><p>​与无链（即在每个算子之后共享数据）相比，我们的链方法显着减少了数据共享开销。链长为9时，数据共享开销仅为无链的9%。然而，由于填充，计算延迟增加了 61%，导致与无链相比更多的延迟。此示例中的最佳长度应为 8，与无链相比，性能提高了 42%。</p><ul><li><strong>Chain searching algorithm</strong></li></ul><p>​为了找到在 DL 模型的数据共享和计算开销之间取得最佳权衡的链，我们设计了如算法 1 所示的链搜索算法</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116223353017.png" alt="image-20221116223353017"></p><p>​对于这个 NP 问题，它是一个类似贪心的算法，它搜索到当前算子为止延迟最少的链。</p><p>​输入：输入是无链的最佳分区方案</p><p>​输出：输出是一组有最小总延迟的算子链（每个链都有分区维度dim,ratio,chained operators这些设置）</p><p>​算法思路<br>① 从一个不在任何链上的算子开始，对每一个可能的ρ，该算法不断链接更多的算子来计算与无链状况下的增益。<br>② 当再添加一个算子没有任何收益时停止<br>③ 此过程中，ρ 与 此链相关的最大链收益都会被记录下来，遍历完所有可能的ρ之后，最终记录到链的参数中。<br>④ 然后算法开始进行找下一个链</p><p>ρ的大小在第一个算子的ρ的附近。<br>要将下一个算子添加到链中，我们需要将链上的每个前面的算子调整为新的填充大小，并使用延迟预测器重新计算总延迟。鉴于该算法检查每个运算符的次数等于比率范围的大小，搜索空间为<img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116224053725.png" alt="image-20221116224053725"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116224125346.png" alt="image-20221116224125346"></p><h3 id="5-NON-LINEARITY-AND-CONCURRENCY-AWARE-LATENCY-PREDICTION"><a href="#5-NON-LINEARITY-AND-CONCURRENCY-AWARE-LATENCY-PREDICTION" class="headerlink" title="5 NON-LINEARITY- AND CONCURRENCY-AWARE LATENCY PREDICTION"></a>5 NON-LINEARITY- AND CONCURRENCY-AWARE LATENCY PREDICTION</h3><p>​CoDL 的分区和算子链技术依赖于算子协同执行的延迟预测。然而，挑战在于如何同时实现精确和轻量化。当前可用的延迟预测器中，由于两个原因不能很好地达到这个目的：</p><ol><li>这些预测器都没有考虑数据共享开销</li><li>由于缺乏底层平台的知识，预测器不能同时准确和轻量级</li></ol><p>​本节介绍我们的预测器设计。它可以通过以下方式实现精确和轻量化：</p><ol><li>包括共同执行的所有数据共享开销</li><li>公式化地制定由平台特征引起的非线性延迟响应，从而降低学习难度。</li></ol><p>输入：算子的超参数，分区维度，比例，是否为链的标记</p><p>输出：给定平台上运算符共同执行的预测延迟</p><h4 id="5-1-Latency-composition-of-concurrency"><a href="#5-1-Latency-composition-of-concurrency" class="headerlink" title="5.1 Latency composition of concurrency"></a>5.1 Latency composition of concurrency</h4><p>​算子共同执行的完整步骤包括：数据转换、映射、预同步、计算、后同步和取消映射。本小节讨论如何对与数据共享相关的延迟进行建模</p><p>​我们首先测量一系列特征图配置的延迟，以了解数据共享的延迟。转换、映射和取消映射步骤的测量时间是相应的 GPU 内核&#x2F;命令运行时间。预同步的测量时间是GPU映射完成和CPU确认完成的时间差。同理，post-sync的测量时间是CPU计算完成和GPU确认完成的时间差。</p><p>​我们的测量表明，映射、同步和数据转换会在 CPU 和 GPU 上的算子协同执行中产生明显的开销。在预测器中不能忽略它们。相比之下，unmapping 和 postsync 的开销很小（~50 μs），这在我们的预测器中被排除在外。</p><p>​因此，算子共同执行的总预测延迟</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116230930275.png" alt="image-20221116230930275"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116230943360.png" alt="image-20221116230943360"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116231104135.png" alt="image-20221116231104135"></p><p>​𝑇𝑡𝑟𝑎𝑛𝑠 and 𝑇𝑚𝑎𝑝与数据大小有明确的线性关系，因为它们大多是内存操作，我们使用以数据大小为特征的线性回归来学习延迟。对于预同步开销 𝑇𝑝𝑠𝑦𝑛𝑐，根据我们的测量，它没有明显的特征。𝑇𝑝𝑠𝑦𝑛𝑐 主要取决于供应商的驱动程序实现。因此，我们使用测量的上限1ms 作为 𝑇𝑝𝑠𝑦𝑛𝑐。</p><h4 id="5-2-Non-linearity-extracted-computing-latency-prediction"><a href="#5-2-Non-linearity-extracted-computing-latency-prediction" class="headerlink" title="5.2 Non-linearity-extracted computing latency prediction"></a>5.2 Non-linearity-extracted computing latency prediction</h4><p>​当前精确延迟预测器的高复杂度是捕捉对算子超参数的非线性延迟响应。为了降低复杂性，我们首先分析非线性的原因并直接在预测器中对其公式化。非线性延迟响应主要有两个原因：</p><ol><li>首先，不同的算法对超参数的规模有不同的延迟响应。卷积算子根据超参数采用不同的算法，例如用于 3×3 的 Winograd 和用于 5×5 卷积的直接卷积。</li><li>其次，不同级别的数据块导致阶梯式延迟响应，GPU 内核执行有两个级别的块，即分别用于内核间和内核内并行的work group和 warp。如果张量大小不能完全除以块大小，就会有空闲的 ALU 或内核。例如，如果工作组的大小为 (2,5,10)，即 100 个线程，并且 warp 大小为 64，则工作组必须在两个 warp 中执行。因此，这块会导致阶梯式延迟响应。同样，对于 CPU，张量也必须被分成块并分配到每个 CPU 内核上运行。然后，为了利用SIMD（单指令多数据）单元，内核中也有一个基本的执行单元，例如TFLite框架中实现的8×8</li></ol><p><strong>Formulating non-linearity.</strong></p><p>​基于以上分析，我们将不同算法和块引起的非线性进行了公式化，并将内核延迟预测抽象为公式3。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116232202836.png" alt="image-20221116232202836"></p><p>𝑆𝑖𝑧𝑒𝑜𝑢𝑡𝑝𝑢𝑡：分区输出大小，通过预测器输入（算子超参数，dim，ρ）来计算给每个处理器用。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116232632014.png" alt="image-20221116232632014"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116232716883.png" alt="image-20221116232716883"></p><p>​等式中唯一的需要学习的变量是<em>t𝑏𝑎𝑠𝑖𝑐𝑈𝑛𝑖𝑡</em>，在给定处理器上执行一个基本单元的时间。它依赖于运算符超参数、内核实现、硬件资源和调度，难以解析建模。因此，我们可以从真正的处理器分析中了解每个内核实现的特性。既然已经提取了非线性，一个极轻线性回归模型可以用来学习t𝑏𝑎𝑠𝑖𝑐𝑈𝑛𝑖𝑡并达到较高的精度。这个模型的Features是（𝐻 , 𝑊 , 𝐼𝐶, 𝑂𝐶）。因为它很轻量，所以它可以在手机设备上被训练通过梯度下降。根据算法的不同，一个算子可以在多个内核中进行运算。处理器的计算时间就是所有内核计算时间的总和。</p><h3 id="6-IMPLEMENTATION"><a href="#6-IMPLEMENTATION" class="headerlink" title="6 IMPLEMENTATION"></a>6 IMPLEMENTATION</h3><p>​我们基于MACE实现CoDL, MACE[19]是移动设备上广泛使用的DL推理框架，在我们的评估中也具有SOTA性能。我们将CoDL的核心功能，即混合类型友好型数据共享和轻量级延迟预测器集成到Mace中。我们通过预编译的共享库来交付这些功能。因此，CoDL也可以很容易地适应到其他推理框架中。CoDL支持DL模型中常用算子的协同执行，包括卷积、完全连接和池化。</p><p>​为了在CPU和GPU上实现混合类型友好的数据共享，我们构建了基于OpenCL api的共享库。具体来说，我们使用Buffer和Image2D分别创建缓冲区和图像类型数据。我们实现了一个OpenCL内核来在缓冲区和图像类型之间转换数据。一旦数据被转换，我们使用enqueueMapBuffer来映射数据，使用enqueueUnmapMemO- object来取消映射。</p><p>​为了实现轻量级延迟预测器，我们使用了多特征线性回归模型。为了训练预测器，我们收集了数据转换、映射和计算的样本。对于数据转换和映射，我们使用数据大小作为特征。对于计算，我们使用(𝐻,𝑊 , 𝐼𝐶, 𝑂𝐶)作为特征。</p><p>​总之，我们在第7节中总共从5个DL模型中收集了大约6000个样本。我们在采样期间将CPU和GPU频率固定为最大值。我们运行算子从H到OC，ρ从0.1到1。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221116233836196.png" alt="image-20221116233836196">我们使用70%的样本作为训练集，剩下的用于测试。我们将学习率设置为0.1，并对预测器进行大约1000个周期的训练。</p><h3 id="7-EVALUATION"><a href="#7-EVALUATION" class="headerlink" title="7 EVALUATION"></a>7 EVALUATION</h3><h4 id="7-1-Experiment-setup"><a href="#7-1-Experiment-setup" class="headerlink" title="7.1 Experiment setup"></a>7.1 Experiment setup</h4><p><strong>Platforms</strong></p><p>Snapdragon 855, 865, 888 and Kirin 990.</p><p><strong>Models</strong></p><p>RetinaFace (RF), YOLOv2 (YOLO) , VGG-16 (VGG) , PoseNet (PN)  and Fast Style Transfer (FST) </p><p>它们由不同数量的算子组成，从14到61不等。我们在float32中执行这些模型。每个实验进行50次，得到平均结果。</p><p><strong>Baselines</strong></p><ul><li>𝜇Layer-like :通过FLOPS进行延迟预测，在CPU与FPU上进行并行运算，但是使用的都是buffer-type</li><li>MACE：单处理器机进行推理，但使用的是友好型的数据结构</li><li>计算并行执行系统的理论性能上限：排除数据共享开销，对每个算子总是采取最佳分区比例</li></ul><h4 id="7-2-Overall-performance"><a href="#7-2-Overall-performance" class="headerlink" title="7.2 Overall performance"></a>7.2 Overall performance</h4><p>除非另有说明，CoDL在Snapdragon平台上使用图像类型。结果如图15所示。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117220353949.png" alt="image-20221117220353949"></p><p>​提升原因：</p><ol><li>CoDL 在 CPU 和 GPU 上利用硬件友好的数据类型来充分利用处理器</li><li>CoDL 利用混合维度和算子链来减少数据共享开销</li><li>CoDL 使用准确的延迟预测器来平衡工作负载分区</li></ol><p>​更重要的是，CoDL接近理论性能上限，因为CoDL成功地减少了数据共享开销，并通过精确的延迟预测器应用了最佳的分区比例。</p><p>​在麒麟990处理器上，Mali GPU具有L1缓存，使其更有效地访问缓冲区类型的数据。因此，CoDL在麒麟平台的CPU和GPU上都使用了缓冲区类型</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117220632515.png" alt="image-20221117220632515"></p><h4 id="7-3-Performance-of-the-hybrid-dimension-partitioning"><a href="#7-3-Performance-of-the-hybrid-dimension-partitioning" class="headerlink" title="7.3 Performance of the hybrid-dimension partitioning"></a>7.3 Performance of the hybrid-dimension partitioning</h4><p>​我们使用骁龙855作为平台。我们不应用运算符链。我们首先展示了由CoDL决定的划分维度在所选模型上的分布。</p><p>​<img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117220823061.png" alt="image-20221117220823061"></p><p>​如图17所示，CoDL通过考虑冗余并发和计算开销来选择分区维度。77%的H分区和23%的OC分区。同时，H维度更有可能用于上面的层，而对于下面的层，更倾向于使用OC。这是因为常见的模型通常在上层具有较大的特征图，其中H分区更有效，以避免 CPU 和 GPU 之间的冗余数据共享。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117221119922.png" alt="image-20221117221119922"></p><p>​图18展示了在Snapdragon 855上使用和不使用所提出的混合维划分的推理延迟。</p><h4 id="7-4-Performance-of-the-operator-chain"><a href="#7-4-Performance-of-the-operator-chain" class="headerlink" title="7.4 Performance of the operator chain"></a>7.4 Performance of the operator chain</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117221250107.png" alt="image-20221117221250107"></p><p>​在选定的模型上，平均超过72%的操作符可以链接在一起，这大大降低了数据共享开销。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117221330378.png" alt="image-20221117221330378"></p><p>​图20说明了有和没有操作链的数据共享开销。由于减少了冗余数据转换和数据共享时间，对于所选模型，带有操作链的CoDL平均减少了55%的开销。</p><h4 id="7-5-Performance-of-the-latency-predictor"><a href="#7-5-Performance-of-the-latency-predictor" class="headerlink" title="7.5 Performance of the latency predictor"></a>7.5 Performance of the latency predictor</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117221539494.png" alt="image-20221117221539494"></p><p>​我们将基于flops的预测器作为基准，在SOTA推理系统中使用。基于flops的预测器考虑模型的flops个数，建立一个简单的线性模型来预测延迟。如图所示，基于flops的预测器在测试平台上的平均准确率仅为8.95%。考虑到非线性特性和并发开销，我们的延迟预测器在测试平台上的平均准确率分别为84.03%、85.17%和82.96%。准确的延迟预测导致CPU和GPU之间平衡的工作负载分区，这反过来加快了推断。</p><p>​更重要的是，所实现的精度甚至可以与黑盒延迟预测模型相媲美，例如nn-meter。在了解硬件特性的基础上，设计了针对移动soc的小而有效的预测器。我们的预测器的模型大小只有500字节左右，而nn-meter的大小接近800 MB，不适合在移动设备上进行在线预测</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117221833026.png" alt="image-20221117221833026"></p><p>​此外，所提出的预测器是非常轻量级的。每次预测只需要0.2-0.5ms。对于预测器，我们收集了大约6000个样本。这种一次性工作在目标设备上花费大约1.5小时。根据我们的评估，训练过程大约需要1-2秒。</p><h4 id="7-6-System-overhead"><a href="#7-6-System-overhead" class="headerlink" title="7.6 System overhead"></a>7.6 System overhead</h4><p>接下来，我们从功率、能量消耗和内存使用方面评估CoDL的系统开销</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117222350506.png" alt="image-20221117222350506"></p><p>​与MACE上的CPU和GPU相比，CoDL的平均功耗分别提高了28.9%和129.5%。</p><p>​CoDL利用了对CPU和GPU友好的数据类型，导致了更高的硬件利用率，功耗增加了22.2%，相比于使用统一数据类型的μplayer。</p><p>​图21b显示了CoDL每次推理的平均能耗以及所选模型的基线。</p><p>​与MACE上的CPU推断相比，我们降低了将近38.7%的能耗。CoDL还可以比μplayer平均节省62.3%的能源成本。但与MACE上的GPU相比，CoDL的能耗增加了52.0%。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/image-20221117222746827.png" alt="image-20221117222746827"></p><p>​为了支持协同执行，CoDL分配额外的内存。如图所示，在所选模型上，CoDL比MACE多消耗大约25.97%的内存。例如，当执行VGG时，CoDL总共使用大约909.02 MB内存，而MACE大约占用645.55 MB内存。</p><h4 id="8-DISCUSSION"><a href="#8-DISCUSSION" class="headerlink" title="8 DISCUSSION"></a>8 DISCUSSION</h4><p><strong>Generality of CoDL</strong></p><p>​CoDL 是一种软件优化解决方案，旨在解决由于不了解平台特性和数据共享开销而导致的效率问题，从而实现设备上 CPU 和 GPU 的高效并发运行。</p><p>​虽然我们在MACE上实现了CoDL，但并发感知延迟预测和CPU和GPU之间的混合数据共享的思想可以很容易地应用到其他移动深度学习框架，如TensorFlow Lite和MNN。通过分析常用的运算符，CoDL可以自适应地为各种gpu选择处理器友好的数据类型。</p><p>​然而，如果新模型中有一些不受支持的算子，CoDL就需要大量的延迟分析和建模，这将花费更多的时间</p><p><strong>Limitation and future work</strong></p><p>​两大局限：</p><ol><li>首先，由于 CPU 和 GPU 的并发运行，CoDL 比单处理器解决方案消耗更多的功率。我们计划在DNN模型推理的基础上扩展预测器来对CPU和GPU的功耗行为进行建模，这样CoDL就可以在能量消耗和延迟之间取得平衡。</li><li>其次，CoDL 很难实现 MobileNet等轻量级 DL 模型的加速，因为分区导致的数据共享开销很容易支配小型算子 CPU 和 GPU 并发运行带来的增益。</li></ol><p>​在未来的工作中，为了适应更动态的工作负载，我们计划扩展预测器，根据CPU和GPU利用率来调整预测的延迟。这样，分区规划可以更灵活。但这并不是一个简单的问题，因为后台存在复杂的资源调度和竞争。</p><p>​对于利用早期终止的模型等实时工作负载，我们可以记录模型中每个终止点的终止概率。在多次执行模型后，每个点的终止概率收敛。然后，CoDL可以根据每个点的终止概率来制定分区计划，这样分区执行平均来说更有效。</p><p><strong>Extended discussion.</strong></p><p>​这项工作表明，移动SoC的具体设计，即CPU和GPU共享内存，是CPU和GPU并行运行能够加速DL模型推理的根本原因。但是，它涉及数据共享开销，包括数据转换和同步。为了解决这个问题，一个专用的基于硬件的数据转换器对于减少数据转换开销非常有帮助。此外，OpenCL的更好实现可以减少同步开销。</p><h4 id="9-RELATED-WORK"><a href="#9-RELATED-WORK" class="headerlink" title="9 RELATED WORK"></a>9 RELATED WORK</h4><p><strong>Co-execution of heterogeneous processors.</strong></p><p>​一些现有的工作探索了同时利用设备上的CPU和GPU来优化移动设备上的DL性能。</p><p>​OPTIC 调优CPU和GPU的工作负载分区和核心频率，使其保持在热约束范围内。</p><p>​μplayer 同时使用CPU和GPU，通过数据量化和工作负载分区来加速DL推理。但是与CoDL相比，它忽略了协同执行中真正的性能问题，如数据共享开销和由硬件特性引起的非线性响应延迟。通过考虑这些因素，CoDL成功地减少了数据共享开销，并最佳地平衡了工作负载分区</p><p>​ 此外，CoDL有助于减少每个DL模型推理的延迟，而这不能通过流水线并行来实现</p><p><strong>Performance prediction for DL inference.</strong></p><p>​已有的研究通过设计延迟预测模型来寻找高效的模型体系结构。cai 提出了一个以模型配置参数为特征的多项式回归模型，但该模型无法捕捉到底层平台特征的影响，而它在实践中可能占主导地位。nn-Meter在运行时考虑了多个算子的融合，使用黑盒随机森林模型预测时延。与现有工作不同的是，CoDL中的预测器考虑了处理器特性引起的延迟模式和并发特定的开销，使得预测器明显更加轻便和准确。</p><p><strong>Acceleration of DL inference on mobile devices.</strong></p><p>​许多工作都在努力更好地利用设备上的处理器来加速DL推理</p><h3 id="10-CONCLUSION"><a href="#10-CONCLUSION" class="headerlink" title="10 CONCLUSION"></a>10 CONCLUSION</h3><p>​在本文中，我们提出了一种用于高效DL推断的CPU-GPU协同执行框架CoDL。CoDL智能地平衡了数据共享和计算的开销，方法是从混合维度对操作符进行自适应划分，并将操作符链接起来以减少数据共享时间。此外，通过设计一个轻量级但精确的延迟预测器，CoDL公平地将工作负载分配到异构处理器上，该预测器考虑了联合执行的开销和非线性平台特性。我们在主流硬件平台上对CoDL进行了评估，结果表明，与SOTA协同执行系统相比，CoDL的平均速度提高了3.43×，节能62.3%。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MobiSys</tag>
      
      <tag>notes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计算机网络第第一章 概述</title>
    <link href="/2022/11/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    <url>/2022/11/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="计算机网络第一章-概述"><a href="#计算机网络第一章-概述" class="headerlink" title="计算机网络第一章 概述"></a>计算机网络第一章 概述</h2><h3 id="1-1-互联网概述及组成"><a href="#1-1-互联网概述及组成" class="headerlink" title="1.1 互联网概述及组成"></a>1.1 互联网概述及组成</h3><h4 id="互联网的两个重要基本特点"><a href="#互联网的两个重要基本特点" class="headerlink" title="互联网的两个重要基本特点"></a>互联网的两个重要基本特点</h4><ul><li>连通性：使上网用户之间都可以交换信息(数据，以及各种音频视频) ，好像这些用户的计算机都可以彼此直接连通一样。</li><li>共享：即资源共享</li></ul><p>​&#x3D;&#x3D;互连网&#x3D;&#x3D;是网络的网络，网络把许多计算机连接在一起，而互连网则把许多网络通过路由器连接在一起。与网络相连的计算机常称为主机（host）。</p><hr><h4 id="互联网基础结构发展的三个阶段"><a href="#互联网基础结构发展的三个阶段" class="headerlink" title="互联网基础结构发展的三个阶段"></a>互联网基础结构发展的三个阶段</h4><p>​一、单个网络ARPANET向互连网发展的过程</p><p>​<em>注意区分internet和Internet，以小写字母i开头的internet（互连网）是一个通用名词，它泛指由多个计算机网络互连而成的计算机网络；以大写字母I开头的Internet（互联网&#x2F;因特网）则是一个专用名词，它指当前全球最大的、开放的、由众多网络相互连接而成的特定互连网，它采用TCP&#x2F;IP协议族作为通信的规则</em></p><p>​二、建成了三级结构的互联网</p><p>​三、逐渐形成了多层次ISP结构的互联网，同时出现了新的名词概念：互联网服务提供者ISP（Internet Service Provider）。</p><hr><h4 id="互联网的组成"><a href="#互联网的组成" class="headerlink" title="互联网的组成"></a>互联网的组成</h4><p>​从互联网的工作方式上来看，可以划分为以下两大块：</p><h5 id="（1）边缘部分"><a href="#（1）边缘部分" class="headerlink" title="（1）边缘部分"></a>（1）边缘部分</h5><p>​由所有连接在互联网上的主机组成。这部分是用户直接使用的，用来进行通信（传送数据、音频或视频）和资源共享。</p><p>​在网络边缘的端系统之间的通信方式通常可以划分为两大类：客户-服务器方式（C&#x2F;S方式）和对等方式（P2P方式）。</p><ul><li>客户-服务器方式<br>客户是服务请求方，服务器是服务提供方。</li><li>对等连接方式</li></ul><h5 id="（2）核心部分"><a href="#（2）核心部分" class="headerlink" title="（2）核心部分"></a>（2）核心部分</h5><p>​由大量网络和连接这些网络的路由器组成。这部分是为边缘部分提供服务的（提供连通性和交换）。</p><hr><h4 id="端到端原则最大的特点是什么，为什么要这么做？"><a href="#端到端原则最大的特点是什么，为什么要这么做？" class="headerlink" title="端到端原则最大的特点是什么，为什么要这么做？"></a><strong>端到端原则最大的特点是什么，为什么要这么做？</strong></h4><ul><li>边缘智能，核心简单：端系统处理能力日益增强，用软件来增强网络协议的处理能力，性价比不断提高，降低网络的复杂性，等价于提升网络的传输速率，也等价于增强网络适应新兴应用的灵活性，降低网络的负担，使网络处理能力都用于交换分组。</li></ul><hr><h4 id="路由器之间采用分组交换的模式。"><a href="#路由器之间采用分组交换的模式。" class="headerlink" title="路由器之间采用分组交换的模式。"></a>路由器之间采用分组交换的模式。</h4><p><strong>分组交换工作要点：单个分组（整个报文一部分）传送到相邻结点，存储下来后查找转发表，转发到下一结点。</strong></p><ul><li><p>1、在发送端，先把较长报文划分成较短的、固定长度的数据段；</p></li><li><p>2、每个数据段前面添加首部构成分组；</p></li><li><p>3、以“分组”作为传送的数据单元，依次把各分组发送到接收端；</p></li><li><p>4、接收端把收到的数据恢复成原来的报文。</p></li><li><p>分组交换的优点：高效、灵活、迅速、可靠</p></li></ul><table><thead><tr><th>优点</th><th>所采用的手段</th></tr></thead><tbody><tr><td>高效</td><td>在分组传输的过程中<strong>动态分配传输带宽</strong>，对通信链路<strong>逐段占用</strong></td></tr><tr><td>灵活</td><td>为每一个分组<strong>独立地选择最合适的转发路由</strong></td></tr><tr><td>迅速</td><td>以分组作为传送单位，不先建立连接就能向其他主机发送分组</td></tr><tr><td>可靠</td><td>保证可靠性的网络协议；分布式多路由的分组交换网，使网络有很好的生存性</td></tr></tbody></table><hr><h4 id="电路交换、分组交换、报文交换的特点、方式、效率、对比"><a href="#电路交换、分组交换、报文交换的特点、方式、效率、对比" class="headerlink" title="电路交换、分组交换、报文交换的特点、方式、效率、对比"></a>电路交换、分组交换、报文交换的特点、方式、效率、对比</h4><table><thead><tr><th align="left">交换类型</th><th>特点</th></tr></thead><tbody><tr><td align="left">电路交换</td><td>整个报文的比特流连续地从源点直达终点，好像在一个管道中传送</td></tr><tr><td align="left">报文交换</td><td><strong>整个报文</strong>先传送到相邻节点，全部存储下来后查找转发表，转发到下一个节点</td></tr><tr><td align="left">分组交换</td><td>单个分组（这只是<strong>整个报文的一部分</strong>）传送到相邻节点，存储下来以后查找转发表，转发到下一个节点</td></tr></tbody></table><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/ff3fef0895864ca7bf51aae55fec685e.png" alt="在这里插入图片描述"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/3a6c213aa821400ca79aa9b61a3abfe7.png" alt="在这里插入图片描述"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/3abd2be003d048068a1c268fb521325d.png" alt="在这里插入图片描述"></p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/b98cc3ae3e934d6089453ea388aa154a.png" alt="在这里插入图片描述"></p><p><strong>总结</strong></p><ul><li>若要连续发送大量数据，且其传送时间远大于连接建立时间，则电路交换的传输速率较快。</li><li>报文交换和分组交换不需要预先分配传输带宽，在传送突发数据时可提高整个网络的信道利用率。</li><li>由于一个分组的长度往往远小于整个报文的长度，因此分组交换比报文交换的时延小，同时也具有更好的灵活性。</li><li>在过去很长的时期，人们都有这样的概念：电路交换适合于话音通信，而分组交换则适合于数据通信。然而随着蜂窝移动通信的发展，这种概念已经发生了根本的变化。从第四代蜂窝移动通信网开始，无论是话音通信还是数据通信，都要采用分组交换。</li></ul><hr><h3 id="1-2-计算机网络的类别、性能指标"><a href="#1-2-计算机网络的类别、性能指标" class="headerlink" title="1.2 计算机网络的类别、性能指标"></a>1.2 计算机网络的类别、性能指标</h3><h4 id="计算机网络的类别"><a href="#计算机网络的类别" class="headerlink" title="计算机网络的类别"></a>计算机网络的类别</h4><ul><li><strong>按照网络作用范围分类</strong><ul><li>广域网</li><li>城域网</li><li>局域网</li><li>个人区域网</li></ul></li><li><strong>按照拓扑结构</strong><ul><li><strong>总线型结构</strong> 优点：结构简单 ，缺点：单点故障可能会影响全网<img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/e80492ca511e436baedf47b33494b0d3.png" alt="img" style="zoom:50%;" /></li><li><strong>星型结构</strong> 优点：扩展方便 ，缺点：对中心节点的依赖较大<img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/1e1ae4975a444967b9971ba21c107462.png" alt="img" style="zoom:50%;" /></li><li><strong>树型结构</strong>  优点：扩展方便， 缺点：对非叶子节点的依赖大<img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/6bb26f8fc2f644aeaf12a2ff7634c108.png" alt="img" style="zoom:50%;" /></li><li><strong>环型结构</strong> 优点：结构简单，扩展方便，缺点：单点故障可能会影响全网<img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/8ba52fcbfd204e61b899b7af24e22998.png" style="zoom:50%;" /></li><li><strong>网状结构</strong> 优点：扩展方便 ， 缺点：冗余太多<img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/8eb53ab535fc4258b96bdce6e2d5b6d5.png" alt="img" style="zoom:50%;" /></li></ul></li></ul><h4 id="计算机网络的性能指标"><a href="#计算机网络的性能指标" class="headerlink" title="计算机网络的性能指标"></a>计算机网络的性能指标</h4><ol><li><p><strong>速率</strong></p><p>也称数据率或比特率，其中$4 \times 10^{10} bit&#x2F;s$的数据率就记为$40 Gbit&#x2F;s$。</p></li><li><p><strong>带宽</strong></p><p>在计算机网络中，带宽用来表示某通道在网络中传送数据的能力，也就是“最高数据率”。带宽的单位也就是数据率低单位$bit&#x2F;s$</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/9c547cba9e1d4fe398aad7b7e97815ba.png" alt="img"></p></li><li><p><strong>吞吐量</strong></p><p>表示在单位时间内通过某个网络（或信道、接口）的实际的数据量。（吞吐量≤带宽（网络额定速度））</p></li><li><p><strong>时延</strong></p><p>网络中的时延由以下几个不同的部分组成：</p><p>（1）发送时延（<del>传输时延</del>） $发送时延 &#x3D; \frac{数据帧长度(bit)}{发送速率(bit&#x2F;s)}$</p><p>（2）传播时延 $传播时延 &#x3D; \frac{信道长度(m)}{电磁波在信道上的传播速率(m&#x2F;s)}$</p><p>（3）处理时延 主机或路由器在收到分组后要话费一定的时间进行处理</p><p>（4）排队时延 分组进入路由器后要先在输入队列中排队等待处理</p><p>网速高指的是发送速率高而不是指传播速率高</p></li><li><p><strong>时延带宽积</strong></p><p>又称为以比特为单位的链路长度，$时延带宽积 &#x3D; 传播时延 \times 带宽$</p></li><li><p><strong>往返时间RTT</strong></p><p>即双向交互一次所需的时间</p></li><li><p><strong>利用率</strong></p><p>分为信道利用率和网络利用率。信道利用率并非越高越好。当网络的利用率接近最大值1时，网络的时延就趋于无穷大。</p><hr><p><strong>“在高速链路（或高带宽链路）上，比特会传送得更快些”（×）</strong></p></li></ol><p>​对于高速网络链路，我们提高的仅仅是数据的发送速率而不是比特在链路上的传播速率。提高链路带宽减小了数据的发送时延。 宽带链路和窄带链路上比特的传播速率是一样的。</p><hr><h3 id="1-3-计算机网络的体系结构"><a href="#1-3-计算机网络的体系结构" class="headerlink" title="1.3 计算机网络的体系结构"></a>1.3 计算机网络的体系结构</h3><h4 id="计算机网络体系结构"><a href="#计算机网络体系结构" class="headerlink" title="计算机网络体系结构"></a>计算机网络体系结构</h4><p>​开放系统互连基本参考模型OSI&#x2F;RM</p><hr><h4 id="网络协议三要素"><a href="#网络协议三要素" class="headerlink" title="网络协议三要素"></a><strong>网络协议三要素</strong></h4><ul><li>语法：数据与控制信息的结构或格式 。</li><li>语义：需要发出何种控制信息，完成何种动作以及做出何种响应。 </li><li>同步：事件实现顺序的详细说明。</li></ul><hr><h4 id="网络为什么要分层？"><a href="#网络为什么要分层？" class="headerlink" title="网络为什么要分层？"></a><strong>网络为什么要分层？</strong></h4><ul><li>解决网络的异构性、复杂性；</li><li>要实现互操作性，使用不同媒介连接起来的不同设备和网络系统在不同的应用环境下实现互操作性，并满足各种业务的需求。营造一种“生存空间”——任何厂商的任何产品、以及任何技术只要遵守这个空间的行为规则，就能够在其中生存并发展。</li><li>把复杂的网络互联问题划分为若干个较小的、单一的问题，在不同层上予以解决.</li><li>层次结构方法包括三个内容：分层及每层功能，服务与层间接口，协议。</li><li><strong>多层通信的实质</strong>：<ul><li>对等层实体之间虚拟通信;</li><li>下层向上层提供服务;</li><li>实际通信在最底层完成;</li></ul></li><li>好处： 各层之间是独立的;灵活性好;结构上可分割开;易于实现和维护;能促进标准化工作。</li></ul><hr><h4 id="三种分层结构体系"><a href="#三种分层结构体系" class="headerlink" title="三种分层结构体系"></a>三种分层结构体系</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/a6364c11eb984d059ed975b7199fde7d.png" alt="在这里插入图片描述"></p><p>​OSI模型共七层协议体系结构，从上到下依次是：应用层，表示层，会话层，运输层，网络层，数据链路层，物理层</p><p>​TCP&#x2F;IP模型共四层协议体系结构，从上到下依次是：应用层，运输层，网际层，网络接口层</p><hr><h4 id="具有五层协议的体系结构"><a href="#具有五层协议的体系结构" class="headerlink" title="具有五层协议的体系结构"></a>具有五层协议的体系结构</h4><p><strong>协议数据单元PDU</strong></p><p>​OSI 参考模型把<strong>对等层次之间传送的数据单位</strong> 称为该层的 协议数据单元 PDU (Protocol Data Unit)。</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/6cd69a79412e409da8e371a08ace9fd8.png" alt="img"></p><ol><li><p>应用层</p><p>交互的数据单元称为&#x3D;&#x3D;报文&#x3D;&#x3D;</p></li><li><p>运输层</p><p>其数据传输的单位是&#x3D;&#x3D;用户数据报&#x3D;&#x3D;</p></li><li><p>网络层</p><p>传输的数据单元是&#x3D;&#x3D;分组&#x3D;&#x3D;，也称IP数据报</p><p>虚电路服务和数据报服务的区别<br>虚电路服务在传送数据之前，首先通过虚呼叫建立一条虚电路；所有分组沿同一条路径传送，并且按发出顺序到达，类似电路交换，建立连接后，分组中只需携带连接标识，建立连接时可协商参数、QoS、开销等<br>数据报：每个分组单独传送，网络为每个分组单独选路；路径可能不同；分组到达顺序可能与发出顺序不同；分组中需要携带完整的目的地址。</p></li><li><p>数据链路层</p><p>数据单位是&#x3D;&#x3D;帧&#x3D;&#x3D;</p><p>数据帧在链路上传输时有哪些出错情况，如何处理？&#x3D;&#x3D;出错重传，超时重传&#x3D;&#x3D;</p></li><li><p>物理层</p><p>数据单位是&#x3D;&#x3D;比特&#x3D;&#x3D;</p><p><strong>每层的任务</strong></p><table><thead><tr><th>层</th><th>作用</th></tr></thead><tbody><tr><td>应用层</td><td>通过应用进程间的交互来完成特定网络应用</td></tr><tr><td>运输层</td><td>负责向两台主机中进程之间的通信提供通用的数据传输服务</td></tr><tr><td>网络层</td><td>负责为分组交换网上的不同主机提供通信服务</td></tr><tr><td>数据链路层</td><td>在链路上无差错的传送帧</td></tr><tr><td>物理层</td><td>在物理媒体上透明地传输比特流(Bit)</td></tr></tbody></table></li></ol><hr><h4 id="虚电路服务和数据报服务的区别"><a href="#虚电路服务和数据报服务的区别" class="headerlink" title="虚电路服务和数据报服务的区别"></a><strong>虚电路服务和数据报服务的区别</strong></h4><ul><li>虚电路服务在传送数据之前，首先通过虚呼叫建立⼀条虚电路；所有分组沿同⼀条路径传送，并且按发出顺序到达，类似电路交换，建立连接后，分组中只需携带连接标识，建立连接时可协商参数、QoS、开销等</li><li>数据报：每个分组单独传送，网络为每个分组单独选路；路径可能不同；分组到达顺序可能与发出顺序不同；分组中需要携带完整的⽬的地址。</li></ul><hr><h4 id="协议与服务概念上的区别"><a href="#协议与服务概念上的区别" class="headerlink" title="协议与服务概念上的区别"></a>协议与服务概念上的区别</h4><ul><li>本层的服务用户 只能看见服务 而无法看见下面的 协议。即下面的协议对上面的服务用户是&#x3D;&#x3D;透明&#x3D;&#x3D;的。</li><li>协议是&#x3D;&#x3D;“水平的 ”&#x3D;&#x3D;，即协议是控制对等实体之间 通信的规则。</li><li>服务是&#x3D;&#x3D;“垂直的 ”&#x3D;&#x3D;，即服务是由下层向上层通过 层间接口提供的。</li><li>上层使用 服务原语 获得下层所提供的服务。</li></ul><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/a3cc6b9dea764ae38137d2f119b7bd7a.png" alt="img"></p><hr><h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><h4 id="计算模板"><a href="#计算模板" class="headerlink" title="计算模板"></a>计算模板</h4><p>​分清楚，k，M，G的底数是10还是2<br>​10的话，$10^3$,$10^6$,$10^9$（描述数据传输速率）<br>​2的话，$2^{10},2^{20},2^{30}$(描述数的计算，通常后面跟B，而1B&#x3D;8bit)</p><p>​在表示纯的数据的量的时候，以2为底数，10，20，30为指数<br>​在表示数据传输速率的时候，以10为底数，3，6，9为指数</p><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/29ea1669f6994c58867a4a3c653cfec3.png" alt="在这里插入图片描述"></p><p>​对于n个分组，m段链路<br>$$<br>总时延&#x3D;n个分组的发送时延+(m-1)\times1个分组的发送时延+m\times1段链路的传播时延<br>$$</p><h4 id="例题1"><a href="#例题1" class="headerlink" title="例题1"></a>例题1</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/47178ab6ff5646ea9b70e3e56f7b5ae1.png" alt="img"></p><h4 id="例题2"><a href="#例题2" class="headerlink" title="例题2"></a>例题2</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/8ab97ebd7de14d8d83efa322d2053e85.png" alt="img"></p><h4 id="例题3"><a href="#例题3" class="headerlink" title="例题3"></a>例题3</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/3eea7bcbf0f44b4bb066ffa43345d73c.png" alt="img"></p><h4 id="例题4"><a href="#例题4" class="headerlink" title="例题4"></a>例题4</h4><p><img src="https://nuaapeter.oss-cn-nanjing.aliyuncs.com/81bdb0bbca0c4c05bfe157bf5c2a62ef.png" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>notes</tag>
      
      <tag>network</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/11/26/hello-world/"/>
    <url>/2022/11/26/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
